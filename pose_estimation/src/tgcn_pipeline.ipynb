{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282aa4ff",
   "metadata": {},
   "source": [
    "# ASL Recognition with TGCN - Complete Pipeline\n",
    "\n",
    "## üöÄ Improved TGCN with Face Landmarks (553 Nodes)\n",
    "\n",
    "This notebook implements a state-of-the-art ASL recognition system using:\n",
    "\n",
    "- **553 keypoints**: 33 pose + 42 hands + 478 face landmarks\n",
    "- **Advanced preprocessing**: Spatial anchoring, temporal smoothing, interpolation\n",
    "- **Improved graph connectivity**: Anatomical + functional relationships\n",
    "- **Data augmentation**: Spatial and temporal transformations\n",
    "- **WLASL-100 subset**: Focus on quality over quantity\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "- **Input**: MediaPipe keypoint sequences (seq_len, 553, 3)\n",
    "- **Graph**: Enhanced connectivity with face-hand relationships\n",
    "- **Model**: ST-GCN with temporal convolutions\n",
    "- **Target**: 87.60% accuracy on WLASL-100 (literature benchmark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14e965f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch Geometric 2.6.1 loaded\n",
      "üéØ All libraries loaded successfully!\n",
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Progress bars and timing\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "\n",
    "# PyTorch Geometric for GCN\n",
    "try:\n",
    "    import torch_geometric\n",
    "    from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "    from torch_geometric.data import Data, Batch\n",
    "    print(f\"‚úÖ PyTorch Geometric {torch_geometric.__version__} loaded\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch Geometric not found. Install with: pip install torch-geometric\")\n",
    "    raise\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our improved normalization module\n",
    "from normalization import (\n",
    "    ImprovedPoseNormalizer,\n",
    "    create_improved_pose_dataset_class,\n",
    "    create_improved_graph_connectivity,\n",
    "    apply_spatial_augmentation,\n",
    "    apply_temporal_augmentation\n",
    ")\n",
    "\n",
    "print(\"üéØ All libraries loaded successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc298d4",
   "metadata": {},
   "source": [
    "## üìä Configuration and Data Paths\n",
    "\n",
    "Set up all paths and hyperparameters for the training pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11f7b605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Windows-Compatible Configuration:\n",
      "  max_seq_len: 40\n",
      "  num_nodes: 553\n",
      "  num_features: 3\n",
      "  max_classes: 10\n",
      "  test_size: 0.2\n",
      "  batch_size: 32\n",
      "  gcn_hidden: 128\n",
      "  temporal_kernel: 7\n",
      "  dropout: 0.3\n",
      "  num_gcn_layers: 2\n",
      "  num_epochs: 50\n",
      "  learning_rate: 0.002\n",
      "  weight_decay: 0.0001\n",
      "  patience: 10\n",
      "  min_lr: 1e-06\n",
      "  use_mixed_precision: True\n",
      "  pin_memory: True\n",
      "  non_blocking: True\n",
      "  compile_model: False\n",
      "  use_channels_last: False\n",
      "  gradient_accumulation: 1\n",
      "  use_augmentation: True\n",
      "  aug_probability: 0.2\n",
      "  spatial_aug_strength: 0.05\n",
      "  temporal_aug_strength: 0.1\n",
      "  aug_on_gpu: True\n",
      "  num_workers: 8\n",
      "  prefetch_factor: 2\n",
      "  persistent_workers: True\n",
      "\n",
      "üìÅ Data directory: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints\n",
      "üíæ Checkpoint directory: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints\n",
      "\n",
      "üöÄ Enabling Windows-Compatible GPU Optimizations:\n",
      "  ‚úÖ cuDNN benchmark enabled\n",
      "  ‚úÖ TF32 enabled for faster matmul\n",
      "  üìä GPU Memory: 4.0 GB\n",
      "  ‚ö†Ô∏è  Limited GPU memory detected - using conservative settings\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "DATA_DIR = r'f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints'\n",
    "CHECKPOINT_DIR = r'f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints'\n",
    "MODEL_SAVE_PATH = os.path.join(CHECKPOINT_DIR, 'best_tgcn_face_model.pth')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# üöÄ WINDOWS-COMPATIBLE GPU CONFIGURATION FOR SPEED üöÄ\n",
    "CONFIG = {\n",
    "    # Data parameters - OPTIMIZED FOR SPEED\n",
    "    'max_seq_len': 40,          # üöÄ Reduced from 50 to save memory/speed\n",
    "    'num_nodes': 553,           # 33 pose + 42 hands + 478 face\n",
    "    'num_features': 3,          # x, y, z coordinates\n",
    "    'max_classes': 10,         # üöÄ Reduced from 300 for faster training\n",
    "    'test_size': 0.2,           # Train/test split ratio\n",
    "    'batch_size': 32,           # üöÄ DOUBLED from 16 for GPU efficiency\n",
    "    \n",
    "    # Model architecture - OPTIMIZED FOR SPEED\n",
    "    'gcn_hidden': 128,          # üöÄ Reduced from 256 to save memory/speed\n",
    "    'temporal_kernel': 7,       # üöÄ Reduced from 9 for speed\n",
    "    'dropout': 0.3,             # Dropout rate\n",
    "    'num_gcn_layers': 2,        # üöÄ Reduced from 3 for speed\n",
    "    \n",
    "    # Training parameters - OPTIMIZED FOR SPEED\n",
    "    'num_epochs': 50,           # üöÄ Reduced for faster initial results\n",
    "    'learning_rate': 0.002,     # üöÄ Increased for faster convergence\n",
    "    'weight_decay': 1e-4,       # L2 regularization\n",
    "    'patience': 10,             # üöÄ Reduced patience for faster training\n",
    "    'min_lr': 1e-6,             # Minimum learning rate\n",
    "    \n",
    "    # üöÄ WINDOWS-COMPATIBLE GPU OPTIMIZATION SETTINGS üöÄ\n",
    "    'use_mixed_precision': True,  # üöÄ Enable AMP for 2x speed\n",
    "    'pin_memory': True,           # üöÄ Faster CPU->GPU transfer\n",
    "    'non_blocking': True,         # üöÄ Async GPU transfers\n",
    "    'compile_model': False,       # üöÄ DISABLED - Triton not available on Windows\n",
    "    'use_channels_last': False,   # üöÄ DISABLED - Can cause issues on some Windows setups\n",
    "    'gradient_accumulation': 1,   # No gradient accumulation for speed\n",
    "    \n",
    "    # Data augmentation - SIMPLIFIED FOR SPEED\n",
    "    'use_augmentation': True,     # Enable data augmentation\n",
    "    'aug_probability': 0.2,       # üöÄ Reduced from 0.3 for speed\n",
    "    'spatial_aug_strength': 0.05, # üöÄ Reduced for speed\n",
    "    'temporal_aug_strength': 0.1, # üöÄ Reduced for speed\n",
    "    'aug_on_gpu': True,           # üöÄ Move augmentation to GPU\n",
    "    \n",
    "    # DataLoader optimization üöÄ\n",
    "    'num_workers': 8,             # üöÄ Parallel data loading\n",
    "    'prefetch_factor': 2,         # üöÄ Prefetch batches\n",
    "    'persistent_workers': True,   # üöÄ Keep workers alive\n",
    "}\n",
    "\n",
    "print(\"üìã Windows-Compatible Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"üíæ Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# üöÄ Enable Windows-compatible GPU optimizations\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nüöÄ Enabling Windows-Compatible GPU Optimizations:\")\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize cuDNN\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    print(\"  ‚úÖ cuDNN benchmark enabled\")\n",
    "    print(\"  ‚úÖ TF32 enabled for faster matmul\")\n",
    "    \n",
    "    # Check GPU memory\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"  üìä GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    if gpu_memory < 6:\n",
    "        print(\"  ‚ö†Ô∏è  Limited GPU memory detected - using conservative settings\")\n",
    "        CONFIG['batch_size'] = min(CONFIG['batch_size'], 24)\n",
    "        CONFIG['gcn_hidden'] = min(CONFIG['gcn_hidden'], 96)\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected - training will be slow on CPU\")\n",
    "    CONFIG['batch_size'] = 8\n",
    "    CONFIG['use_mixed_precision'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e4f9d",
   "metadata": {},
   "source": [
    "## üîç Data Exploration and Validation\n",
    "\n",
    "Explore the keypoint data to understand the dataset structure and validate the 553-node architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2c7ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Statistics:\n",
      "  Total classes found: 300\n",
      "  about: 8 files, shape: (104, 553, 3)\n",
      "  accident: 13 files, shape: (103, 553, 3)\n",
      "  africa: 13 files, shape: (145, 553, 3)\n",
      "  again: 10 files, shape: (70, 553, 3)\n",
      "  all: 13 files, shape: (82, 553, 3)\n",
      "  always: 9 files, shape: (70, 553, 3)\n",
      "  animal: 10 files, shape: (126, 553, 3)\n",
      "  apple: 13 files, shape: (71, 553, 3)\n",
      "  approve: 11 files, shape: (134, 553, 3)\n",
      "  argue: 10 files, shape: (86, 553, 3)\n",
      "  arrive: 10 files, shape: (107, 553, 3)\n",
      "  baby: 10 files, shape: (72, 553, 3)\n",
      "  back: 7 files, shape: (39, 553, 3)\n",
      "  backpack: 11 files, shape: (36, 553, 3)\n",
      "  bad: 11 files, shape: (70, 553, 3)\n",
      "  bake: 8 files, shape: (98, 553, 3)\n",
      "  balance: 11 files, shape: (102, 553, 3)\n",
      "  ball: 11 files, shape: (55, 553, 3)\n",
      "  banana: 10 files, shape: (79, 553, 3)\n",
      "  bar: 10 files, shape: (62, 553, 3)\n",
      "\n",
      "üìà Sample distribution (top 20):\n",
      "  accident: 13 samples\n",
      "  africa: 13 samples\n",
      "  all: 13 samples\n",
      "  apple: 13 samples\n",
      "  approve: 11 samples\n",
      "  backpack: 11 samples\n",
      "  bad: 11 samples\n",
      "  balance: 11 samples\n",
      "  ball: 11 samples\n",
      "  again: 10 samples\n",
      "\n",
      "üèóÔ∏è Architecture validation:\n",
      "  Most common shape: (70, 553, 3)\n",
      "  Expected nodes: 553 (33 pose + 42 hands + 478 face)\n",
      "  ‚úÖ Architecture matches! Found 553 nodes\n"
     ]
    }
   ],
   "source": [
    "def explore_dataset(data_dir):\n",
    "    \"\"\"Explore the keypoint dataset structure and statistics\"\"\"\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"‚ùå Data directory not found: {data_dir}\")\n",
    "        print(\"Please run the keypoint extraction first with pose_estimation_mediapipe.py\")\n",
    "        return None\n",
    "    \n",
    "    # Find all word directories\n",
    "    word_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    word_dirs = sorted(word_dirs)\n",
    "    \n",
    "    print(f\"üìä Dataset Statistics:\")\n",
    "    print(f\"  Total classes found: {len(word_dirs)}\")\n",
    "    \n",
    "    # Analyze sample distribution\n",
    "    class_stats = []\n",
    "    total_files = 0\n",
    "    sample_shapes = []\n",
    "    \n",
    "    for word in word_dirs[:20]:  # Check first 20 classes\n",
    "        word_dir = os.path.join(data_dir, word)\n",
    "        npz_files = glob.glob(os.path.join(word_dir, \"*.npz\"))\n",
    "        total_files += len(npz_files)\n",
    "        \n",
    "        # Check sample file shape\n",
    "        if npz_files:\n",
    "            try:\n",
    "                sample_data = np.load(npz_files[0])\n",
    "                if 'nodes' in sample_data:\n",
    "                    shape = sample_data['nodes'].shape\n",
    "                    sample_shapes.append(shape)\n",
    "                    print(f\"  {word}: {len(npz_files)} files, shape: {shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {word}: {len(npz_files)} files, error reading: {e}\")\n",
    "        \n",
    "        class_stats.append((word, len(npz_files)))\n",
    "    \n",
    "    print(f\"\\nüìà Sample distribution (top 20):\")\n",
    "    class_stats.sort(key=lambda x: x[1], reverse=True)\n",
    "    for word, count in class_stats[:10]:\n",
    "        print(f\"  {word}: {count} samples\")\n",
    "    \n",
    "    # Validate node architecture\n",
    "    if sample_shapes:\n",
    "        most_common_shape = max(set(sample_shapes), key=sample_shapes.count)\n",
    "        print(f\"\\nüèóÔ∏è Architecture validation:\")\n",
    "        print(f\"  Most common shape: {most_common_shape}\")\n",
    "        print(f\"  Expected nodes: {CONFIG['num_nodes']} (33 pose + 42 hands + 478 face)\")\n",
    "        \n",
    "        if most_common_shape[1] == CONFIG['num_nodes']:\n",
    "            print(f\"  ‚úÖ Architecture matches! Found {most_common_shape[1]} nodes\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Architecture mismatch! Found {most_common_shape[1]}, expected {CONFIG['num_nodes']}\")\n",
    "            if most_common_shape[1] == 75:\n",
    "                print(f\"  üìù Data contains only pose+hands (75 nodes). Need to re-run extraction with face landmarks.\")\n",
    "                return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Explore the dataset\n",
    "data_ready = explore_dataset(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e89d53",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Dataset Class and Data Loading\n",
    "\n",
    "Create the dataset class with improved normalization and load the data for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1da62b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating datasets...\n",
      "Loading IMPROVED dataset from: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints\n",
      "üéØ Using subset of 10 classes for better training\n",
      "Selected top 10 classes with most samples\n",
      "Found 10 word categories\n",
      "Number of classes: 10\n",
      "Total valid files found: 169\n",
      "TRAIN split: 135 files\n",
      "Class distribution in train (showing top 10):\n",
      "  drink: 17 samples\n",
      "  computer: 16 samples\n",
      "  go: 14 samples\n",
      "  before: 13 samples\n",
      "  thin: 13 samples\n",
      "  like: 13 samples\n",
      "  mother: 13 samples\n",
      "  cousin: 12 samples\n",
      "  hot: 12 samples\n",
      "  no: 12 samples\n",
      "Loading IMPROVED dataset from: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints\n",
      "üéØ Using subset of 10 classes for better training\n",
      "Selected top 10 classes with most samples\n",
      "Found 10 word categories\n",
      "Number of classes: 10\n",
      "Total valid files found: 169\n",
      "TRAIN split: 135 files\n",
      "Class distribution in train (showing top 10):\n",
      "  drink: 17 samples\n",
      "  computer: 16 samples\n",
      "  go: 14 samples\n",
      "  before: 13 samples\n",
      "  thin: 13 samples\n",
      "  like: 13 samples\n",
      "  mother: 13 samples\n",
      "  cousin: 12 samples\n",
      "  hot: 12 samples\n",
      "  no: 12 samples\n",
      "Loading IMPROVED dataset from: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints\n",
      "üéØ Using subset of 10 classes for better training\n",
      "Selected top 10 classes with most samples\n",
      "Found 10 word categories\n",
      "Number of classes: 10\n",
      "Total valid files found: 169\n",
      "TEST split: 34 files\n",
      "Class distribution in test (showing top 10):\n",
      "  before: 4 samples\n",
      "  computer: 4 samples\n",
      "  like: 4 samples\n",
      "  drink: 4 samples\n",
      "  go: 3 samples\n",
      "  mother: 3 samples\n",
      "  cousin: 3 samples\n",
      "  thin: 3 samples\n",
      "  no: 3 samples\n",
      "  hot: 3 samples\n",
      "‚úÖ Datasets created successfully!\n",
      "üìä Training samples: 135\n",
      "üìä Test samples: 34\n",
      "üìä Number of classes: 10\n",
      "üìä Batch size: 24\n",
      "üíæ Class mapping saved to f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints/class_mapping.json\n",
      "Total valid files found: 169\n",
      "TEST split: 34 files\n",
      "Class distribution in test (showing top 10):\n",
      "  before: 4 samples\n",
      "  computer: 4 samples\n",
      "  like: 4 samples\n",
      "  drink: 4 samples\n",
      "  go: 3 samples\n",
      "  mother: 3 samples\n",
      "  cousin: 3 samples\n",
      "  thin: 3 samples\n",
      "  no: 3 samples\n",
      "  hot: 3 samples\n",
      "‚úÖ Datasets created successfully!\n",
      "üìä Training samples: 135\n",
      "üìä Test samples: 34\n",
      "üìä Number of classes: 10\n",
      "üìä Batch size: 24\n",
      "üíæ Class mapping saved to f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints/class_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# Create the improved dataset class\n",
    "ImprovedPoseSequenceDataset = create_improved_pose_dataset_class()\n",
    "\n",
    "# Initialize datasets\n",
    "if data_ready:\n",
    "    print(\"üîÑ Creating datasets...\")\n",
    "    \n",
    "    # Training dataset\n",
    "    train_dataset = ImprovedPoseSequenceDataset(\n",
    "        data_dir=DATA_DIR,\n",
    "        max_seq_len=CONFIG['max_seq_len'],\n",
    "        split='train',\n",
    "        test_size=CONFIG['test_size'],\n",
    "        random_state=42,\n",
    "        use_subset=True,\n",
    "        max_classes=CONFIG['max_classes']\n",
    "    )\n",
    "    \n",
    "    # Test dataset\n",
    "    test_dataset = ImprovedPoseSequenceDataset(\n",
    "        data_dir=DATA_DIR,\n",
    "        max_seq_len=CONFIG['max_seq_len'], \n",
    "        split='test',\n",
    "        test_size=CONFIG['test_size'],\n",
    "        random_state=42,\n",
    "        use_subset=True,\n",
    "        max_classes=CONFIG['max_classes']\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Set to 0 for Windows/Jupyter compatibility\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=0,  # Set to 0 for Windows/Jupyter compatibility\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Datasets created successfully!\")\n",
    "    print(f\"üìä Training samples: {len(train_dataset)}\")\n",
    "    print(f\"üìä Test samples: {len(test_dataset)}\")\n",
    "    print(f\"üìä Number of classes: {train_dataset.num_classes}\")\n",
    "    print(f\"üìä Batch size: {CONFIG['batch_size']}\")\n",
    "    \n",
    "    # Save class mapping\n",
    "    class_mapping = {\n",
    "        'word_to_idx': train_dataset.word_to_idx,\n",
    "        'idx_to_word': train_dataset.idx_to_word\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(CHECKPOINT_DIR, 'class_mapping.json'), 'w') as f:\n",
    "        json.dump(class_mapping, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Class mapping saved to {CHECKPOINT_DIR}/class_mapping.json\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot create datasets. Please fix data issues first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891cc429",
   "metadata": {},
   "source": [
    "## üèóÔ∏è TGCN Model Architecture\n",
    "\n",
    "Implement the Temporal Graph Convolutional Network with improved connectivity for 553 nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1aaa9a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TGCN model defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class TemporalGCN(nn.Module):\n",
    "    \"\"\"Temporal Graph Convolutional Network for ASL Recognition\"\"\"\n",
    "    \n",
    "    def __init__(self, num_nodes, num_features, num_classes, \n",
    "                 gcn_hidden=256, temporal_kernel=9, dropout=0.3, num_gcn_layers=3):\n",
    "        super(TemporalGCN, self).__init__()\n",
    "        \n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.gcn_hidden = gcn_hidden\n",
    "        self.temporal_kernel = temporal_kernel\n",
    "        \n",
    "        # Create improved graph connectivity\n",
    "        self.edge_index = create_improved_graph_connectivity()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(num_features, gcn_hidden)\n",
    "        \n",
    "        # GCN layers with residual connections\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        for i in range(num_gcn_layers):\n",
    "            self.gcn_layers.append(GCNConv(gcn_hidden, gcn_hidden))\n",
    "        \n",
    "        # Batch normalization for each GCN layer\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(gcn_hidden) for _ in range(num_gcn_layers)\n",
    "        ])\n",
    "        \n",
    "        # Temporal convolution layers\n",
    "        self.temporal_conv1 = nn.Conv1d(\n",
    "            gcn_hidden, gcn_hidden, \n",
    "            kernel_size=temporal_kernel,\n",
    "            padding=temporal_kernel//2\n",
    "        )\n",
    "        self.temporal_conv2 = nn.Conv1d(\n",
    "            gcn_hidden, gcn_hidden//2,\n",
    "            kernel_size=temporal_kernel,\n",
    "            padding=temporal_kernel//2\n",
    "        )\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.spatial_dropout = nn.Dropout2d(dropout * 0.5)\n",
    "        \n",
    "        # Global pooling and classification\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(gcn_hidden//2, gcn_hidden//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(gcn_hidden//4, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor [batch_size, seq_len, num_nodes, num_features]\n",
    "            \n",
    "        Returns:\n",
    "            logits: Class predictions [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, num_nodes, num_features = x.shape\n",
    "        \n",
    "        # Move edge index to same device as input\n",
    "        edge_index = self.edge_index.to(x.device)\n",
    "        \n",
    "        # Process each frame separately\n",
    "        frame_outputs = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Current frame: [batch_size, num_nodes, num_features]\n",
    "            frame = x[:, t, :, :]\n",
    "            \n",
    "            # Project input features\n",
    "            h = self.input_projection(frame)  # [batch_size, num_nodes, gcn_hidden]\n",
    "            \n",
    "            # Apply GCN layers with residual connections\n",
    "            for i, (gcn, bn) in enumerate(zip(self.gcn_layers, self.batch_norms)):\n",
    "                residual = h if i > 0 else None\n",
    "                \n",
    "                # Reshape for GCN: [batch_size * num_nodes, gcn_hidden]\n",
    "                # Use contiguous() to ensure tensor is contiguous before view\n",
    "                h_flat = h.contiguous().view(-1, h.size(-1))\n",
    "                \n",
    "                # Expand edge index for batch\n",
    "                batch_edge_index = edge_index.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "                batch_edge_index = batch_edge_index + torch.arange(batch_size, device=x.device).view(-1, 1, 1) * num_nodes\n",
    "                batch_edge_index = batch_edge_index.view(2, -1)\n",
    "                \n",
    "                # Apply GCN\n",
    "                h_flat = gcn(h_flat, batch_edge_index)\n",
    "                h = h_flat.view(batch_size, num_nodes, -1)\n",
    "                \n",
    "                # Batch normalization\n",
    "                h = h.permute(0, 2, 1)  # [batch_size, gcn_hidden, num_nodes]\n",
    "                h = bn(h)\n",
    "                h = h.permute(0, 2, 1)  # [batch_size, num_nodes, gcn_hidden]\n",
    "                \n",
    "                # Activation and residual connection\n",
    "                h = F.relu(h)\n",
    "                if residual is not None:\n",
    "                    h = h + residual\n",
    "                \n",
    "                h = self.dropout(h)\n",
    "            \n",
    "            # Spatial dropout for regularization\n",
    "            h = h.unsqueeze(-1)  # [batch_size, num_nodes, gcn_hidden, 1]\n",
    "            h = self.spatial_dropout(h)\n",
    "            h = h.squeeze(-1)   # [batch_size, num_nodes, gcn_hidden]\n",
    "            \n",
    "            # Global spatial pooling for this frame\n",
    "            frame_features = torch.mean(h, dim=1)  # [batch_size, gcn_hidden]\n",
    "            frame_outputs.append(frame_features)\n",
    "        \n",
    "        # Stack frame features: [batch_size, seq_len, gcn_hidden]\n",
    "        temporal_features = torch.stack(frame_outputs, dim=1)\n",
    "        \n",
    "        # Temporal convolution: [batch_size, gcn_hidden, seq_len]\n",
    "        temporal_features = temporal_features.permute(0, 2, 1)\n",
    "        \n",
    "        # Apply temporal convolutions\n",
    "        temporal_features = F.relu(self.temporal_conv1(temporal_features))\n",
    "        temporal_features = self.dropout(temporal_features)\n",
    "        temporal_features = F.relu(self.temporal_conv2(temporal_features))\n",
    "        \n",
    "        # Global temporal pooling\n",
    "        sequence_features = self.global_pool(temporal_features).squeeze(-1)  # [batch_size, gcn_hidden//2]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(sequence_features)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "print(\"‚úÖ TGCN model defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8580f76",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Training Utilities and Metrics\n",
    "\n",
    "Define training utilities, metrics calculation, and progress tracking functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bc17ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training utilities with tqdm progress bars defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class MetricsTracker:\n",
    "    \"\"\"Track training metrics and progress\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "        self.learning_rates = []\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_epoch = 0\n",
    "    \n",
    "    def update(self, train_loss, train_acc, val_loss, val_acc, lr):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.train_accuracies.append(train_acc)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_accuracies.append(val_acc)\n",
    "        self.learning_rates.append(lr)\n",
    "        \n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            self.best_epoch = len(self.val_accuracies) - 1\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        \"\"\"Plot training metrics\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss plot\n",
    "        axes[0, 0].plot(self.train_losses, label='Train Loss', color='blue')\n",
    "        axes[0, 0].plot(self.val_losses, label='Val Loss', color='red')\n",
    "        axes[0, 0].set_title('Training and Validation Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        axes[0, 1].plot(self.train_accuracies, label='Train Acc', color='blue')\n",
    "        axes[0, 1].plot(self.val_accuracies, label='Val Acc', color='red')\n",
    "        axes[0, 1].axhline(y=self.best_val_acc, color='green', linestyle='--', \n",
    "                          label=f'Best Val Acc: {self.best_val_acc:.3f}')\n",
    "        axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Learning rate plot\n",
    "        axes[1, 0].plot(self.learning_rates, color='orange')\n",
    "        axes[1, 0].set_title('Learning Rate Schedule')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # Validation accuracy zoomed\n",
    "        axes[1, 1].plot(self.val_accuracies, color='red', linewidth=2)\n",
    "        axes[1, 1].axhline(y=self.best_val_acc, color='green', linestyle='--')\n",
    "        axes[1, 1].set_title(f'Validation Accuracy (Best: {self.best_val_acc:.3f}% at epoch {self.best_epoch})')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Accuracy (%)')\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    \"\"\"Calculate accuracy from model outputs and targets\"\"\"\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    total = targets.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, use_augmentation=False):\n",
    "    \"\"\"Train for one epoch with tqdm progress bar\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Create progress bar for batches\n",
    "    train_pbar = tqdm(train_loader, desc='Training', leave=False)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_pbar):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Apply data augmentation if enabled\n",
    "        if use_augmentation and np.random.random() < CONFIG['aug_probability']:\n",
    "            # Convert to numpy for augmentation\n",
    "            data_np = data.cpu().numpy()\n",
    "            \n",
    "            # Apply spatial augmentation batch-wise\n",
    "            if np.random.random() < 0.5:\n",
    "                augmented_batch = []\n",
    "                for i in range(data_np.shape[0]):  # Iterate over batch\n",
    "                    # Apply spatial augmentation to each sequence in the batch\n",
    "                    aug_seq = apply_spatial_augmentation(\n",
    "                        data_np[i],  # Shape: [seq_len, num_nodes, num_features]\n",
    "                        scale_range=CONFIG['spatial_aug_strength'],\n",
    "                        translation_range=CONFIG['spatial_aug_strength']\n",
    "                    )\n",
    "                    augmented_batch.append(aug_seq)\n",
    "                data_np = np.array(augmented_batch)\n",
    "            \n",
    "            # Apply temporal augmentation batch-wise  \n",
    "            if np.random.random() < 0.5:\n",
    "                augmented_batch = []\n",
    "                for i in range(data_np.shape[0]):  # Iterate over batch\n",
    "                    aug_seq = apply_temporal_augmentation(\n",
    "                        data_np[i],  # Shape: [seq_len, num_nodes, num_features]\n",
    "                        speed_range=CONFIG['temporal_aug_strength']\n",
    "                    )\n",
    "                    # Ensure consistent length\n",
    "                    if aug_seq.shape[0] != CONFIG['max_seq_len']:\n",
    "                        if aug_seq.shape[0] > CONFIG['max_seq_len']:\n",
    "                            indices = np.linspace(0, aug_seq.shape[0]-1, CONFIG['max_seq_len'], dtype=int)\n",
    "                            aug_seq = aug_seq[indices]\n",
    "                        else:\n",
    "                            padding = np.zeros((CONFIG['max_seq_len'] - aug_seq.shape[0], \n",
    "                                              aug_seq.shape[1], aug_seq.shape[2]))\n",
    "                            aug_seq = np.concatenate([aug_seq, padding], axis=0)\n",
    "                    augmented_batch.append(aug_seq)\n",
    "                data_np = np.array(augmented_batch)\n",
    "            \n",
    "            # Convert back to tensor\n",
    "            data = torch.tensor(data_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        accuracy = calculate_accuracy(outputs, targets)\n",
    "        total_accuracy += accuracy\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{accuracy:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return total_loss / num_batches, total_accuracy / num_batches\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch with tqdm progress bar\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Create progress bar for validation\n",
    "    val_pbar = tqdm(val_loader, desc='Validation', leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_pbar:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            accuracy = calculate_accuracy(outputs, targets)\n",
    "            total_accuracy += accuracy\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{accuracy:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return total_loss / num_batches, total_accuracy / num_batches\n",
    "\n",
    "print(\"‚úÖ Training utilities with tqdm progress bars defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ee451",
   "metadata": {},
   "source": [
    "## üöÄ Model Initialization and Training Setup\n",
    "\n",
    "Initialize the TGCN model and set up the training components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a27f2564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training function with progress bars ready!\n"
     ]
    }
   ],
   "source": [
    "def train_model_with_progress():\n",
    "    \"\"\"Complete training pipeline with progress bars and monitoring\"\"\"\n",
    "    \n",
    "    if not data_ready:\n",
    "        print(\"‚ùå Data not ready. Please run data loading first.\")\n",
    "        return None\n",
    "        \n",
    "    print(\"üöÄ Starting TGCN Training Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìä Dataset: {len(train_dataset)} train, {len(test_dataset)} test\")\n",
    "    print(f\"üéØ Classes: {num_classes}\")\n",
    "    print(f\"üèóÔ∏è  Model: {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    print(f\"‚öôÔ∏è  Device: {device}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize tracking\n",
    "    metrics = MetricsTracker()\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # Create epoch progress bar\n",
    "    epoch_pbar = trange(CONFIG['num_epochs'], desc='üèãÔ∏è Training Epochs', \n",
    "                       position=0, leave=True)\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Training phase with progress bar\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Create batch progress bar\n",
    "        train_pbar = tqdm(train_loader, desc=f'üìà Epoch {epoch+1}/{CONFIG[\"num_epochs\"]}', \n",
    "                         position=1, leave=False)\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(train_pbar):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size = data.size(0)\n",
    "            \n",
    "            # Data augmentation\n",
    "            if CONFIG['use_augmentation'] and np.random.random() < CONFIG['aug_probability']:\n",
    "                augmented_batch = []\n",
    "                for i in range(batch_size):\n",
    "                    seq = data[i].cpu().numpy()\n",
    "                    \n",
    "                    # Apply spatial augmentation\n",
    "                    if np.random.random() < 0.5:\n",
    "                        seq = apply_spatial_augmentation(\n",
    "                            seq, \n",
    "                            scale_range=CONFIG['spatial_aug_strength'],\n",
    "                            translation_range=CONFIG['spatial_aug_strength']\n",
    "                        )\n",
    "                    \n",
    "                    # Apply temporal augmentation\n",
    "                    if np.random.random() < 0.3:\n",
    "                        aug_seq = apply_temporal_augmentation(\n",
    "                            seq, speed_range=CONFIG['temporal_aug_strength']\n",
    "                        )\n",
    "                        \n",
    "                        # Handle sequence length\n",
    "                        if aug_seq.shape[0] > CONFIG['max_seq_len']:\n",
    "                            indices = np.linspace(0, aug_seq.shape[0] - 1, \n",
    "                                                CONFIG['max_seq_len'], dtype=int)\n",
    "                            aug_seq = aug_seq[indices]\n",
    "                        else:\n",
    "                            padding = np.zeros((CONFIG['max_seq_len'] - aug_seq.shape[0], \n",
    "                                              aug_seq.shape[1], aug_seq.shape[2]))\n",
    "                            aug_seq = np.concatenate([aug_seq, padding], axis=0)\n",
    "                        seq = aug_seq\n",
    "                    \n",
    "                    augmented_batch.append(seq)\n",
    "                \n",
    "                data = torch.tensor(np.array(augmented_batch), dtype=torch.float32).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            current_acc = 100. * train_correct / train_total\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_train_loss = train_loss / len(train_loader)\n",
    "        epoch_train_acc = 100. * train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(test_loader, desc='üîç Validation', position=1, leave=False)\n",
    "            for data, targets in val_pbar:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == targets).sum().item()\n",
    "                \n",
    "                current_val_acc = 100. * val_correct / val_total\n",
    "                val_pbar.set_postfix({'Acc': f'{current_val_acc:.2f}%'})\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(test_loader)\n",
    "        epoch_val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Track metrics\n",
    "        metrics.update(\n",
    "            epoch_train_loss, epoch_train_acc,\n",
    "            epoch_val_loss, epoch_val_acc, current_lr\n",
    "        )\n",
    "        \n",
    "        # Update epoch progress bar\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        epoch_pbar.set_postfix({\n",
    "            'Train Acc': f'{epoch_train_acc:.2f}%',\n",
    "            'Val Acc': f'{epoch_val_acc:.2f}%',\n",
    "            'Best': f'{metrics.best_val_acc:.2f}%',\n",
    "            'Time': f'{epoch_time:.1f}s'\n",
    "        })\n",
    "        \n",
    "        # Print detailed epoch summary\n",
    "        print(f\"\\nüìä Epoch {epoch+1}/{CONFIG['num_epochs']} Summary:\")\n",
    "        print(f\"   Train - Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"   Val   - Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.2f}%\")\n",
    "        print(f\"   LR: {current_lr:.6f}, Time: {epoch_time:.1f}s\")\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > metrics.best_val_acc:\n",
    "            metrics.best_val_acc = epoch_val_acc\n",
    "            metrics.best_epoch = epoch\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': epoch_val_acc,\n",
    "                'config': CONFIG\n",
    "            }, MODEL_SAVE_PATH)\n",
    "            \n",
    "            print(f\"   üíæ New best model saved! (Val Acc: {epoch_val_acc:.2f}%)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        # Early stopping\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"\\n‚èπÔ∏è Early stopping triggered after {epoch+1} epochs\")\n",
    "            print(f\"   Best validation accuracy: {metrics.best_val_acc:.2f}% (epoch {metrics.best_epoch+1})\")\n",
    "            break\n",
    "        \n",
    "        # Stop if learning rate is too small\n",
    "        if current_lr < CONFIG['min_lr']:\n",
    "            print(f\"\\n‚èπÔ∏è Learning rate too small ({current_lr:.2e}), stopping training\")\n",
    "            break\n",
    "    \n",
    "    # Training complete\n",
    "    total_time = time.time() - training_start_time\n",
    "    epoch_pbar.close()\n",
    "    \n",
    "    print(f\"\\nüèÅ Training Complete!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚è±Ô∏è  Total time: {total_time/3600:.2f} hours ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"üèÜ Best validation accuracy: {metrics.best_val_acc:.2f}% (epoch {metrics.best_epoch+1})\")\n",
    "    print(f\"üéØ Literature benchmark: 87.60%\")\n",
    "    \n",
    "    if metrics.best_val_acc >= 87.60:\n",
    "        print(f\"üéâ SUCCESS! We achieved the literature benchmark!\")\n",
    "    elif metrics.best_val_acc >= 80.0:\n",
    "        print(f\"‚úÖ EXCELLENT! Strong performance, very close to benchmark\")\n",
    "    else:\n",
    "        print(f\"üìà Good progress! Room for hyperparameter tuning\")\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"‚úÖ Best model restored\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    metrics.plot_metrics()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"‚úÖ Training function with progress bars ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac95a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED Graph: 553 nodes, 308 edges\n",
      "Added face landmarks and enhanced connectivity for ASL recognition\n",
      "üèóÔ∏è Model Architecture:\n",
      "  Total parameters: 117,730\n",
      "  Trainable parameters: 117,730\n",
      "  Model size: 0.45 MB\n",
      "‚úÖ Training setup complete!\n",
      "  Device: cuda\n",
      "  Optimizer: AdamW\n",
      "  Scheduler: ReduceLROnPlateau\n",
      "  Loss function: CrossEntropyLoss\n",
      "\n",
      "üß™ Test forward pass:\n",
      "  Input shape: torch.Size([2, 40, 553, 3])\n",
      "  Output shape: torch.Size([2, 10])\n",
      "  Expected output shape: [2, 10]\n",
      "  ‚úÖ Forward pass successful!\n",
      "\n",
      "üß™ Test forward pass:\n",
      "  Input shape: torch.Size([2, 40, 553, 3])\n",
      "  Output shape: torch.Size([2, 10])\n",
      "  Expected output shape: [2, 10]\n",
      "  ‚úÖ Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "if data_ready:\n",
    "    # Initialize model\n",
    "    model = TemporalGCN(\n",
    "        num_nodes=CONFIG['num_nodes'],\n",
    "        num_features=CONFIG['num_features'],\n",
    "        num_classes=train_dataset.num_classes,\n",
    "        gcn_hidden=CONFIG['gcn_hidden'],\n",
    "        temporal_kernel=CONFIG['temporal_kernel'],\n",
    "        dropout=CONFIG['dropout'],\n",
    "        num_gcn_layers=CONFIG['num_gcn_layers']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"üèóÔ∏è Model Architecture:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"  Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='max',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=CONFIG['min_lr']\n",
    "    )\n",
    "    \n",
    "    # Metrics tracker\n",
    "    metrics = MetricsTracker()\n",
    "    \n",
    "    print(f\"‚úÖ Training setup complete!\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(f\"  Optimizer: AdamW\")\n",
    "    print(f\"  Scheduler: ReduceLROnPlateau\")\n",
    "    print(f\"  Loss function: CrossEntropyLoss\")\n",
    "    \n",
    "    # Test a forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_batch = next(iter(train_loader))\n",
    "        test_data, test_targets = test_batch[0][:2].to(device), test_batch[1][:2].to(device)\n",
    "        test_output = model(test_data)\n",
    "        print(f\"\\nüß™ Test forward pass:\")\n",
    "        print(f\"  Input shape: {test_data.shape}\")\n",
    "        print(f\"  Output shape: {test_output.shape}\")\n",
    "        print(f\"  Expected output shape: [2, {train_dataset.num_classes}]\")\n",
    "        \n",
    "        if test_output.shape == (2, train_dataset.num_classes):\n",
    "            print(f\"  ‚úÖ Forward pass successful!\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Shape mismatch in forward pass!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize model. Please fix data issues first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45697bda",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Core Ultra-Optimized Training Loop\n",
    "\n",
    "This section contains the core ultra-optimized training loop with all GPU enhancements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a678a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_ultra_training_loop(compiled_model, scaler, metrics, best_model_state, \n",
    "                            patience_counter, training_start_time, batch_times, \n",
    "                            epoch_times, samples_per_second):\n",
    "    \"\"\"Core ultra-optimized training loop with all GPU enhancements\"\"\"\n",
    "    \n",
    "    # Create epoch progress bar\n",
    "    epoch_pbar = trange(CONFIG['num_epochs'], desc='üöÄ Ultra-Fast Training', \n",
    "                       position=0, leave=True)\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Training phase with ultra optimizations\n",
    "        compiled_model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Create batch progress bar with speed metrics\n",
    "        train_pbar = tqdm(train_loader, desc=f'‚ö° Epoch {epoch+1}/{CONFIG[\"num_epochs\"]}', \n",
    "                         position=1, leave=False)\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(train_pbar):\n",
    "            batch_iteration_start = time.time()\n",
    "            \n",
    "            # üöÄ Optimized data transfer with non-blocking\n",
    "            if CONFIG['non_blocking']:\n",
    "                data = data.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "            else:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # üöÄ Apply channels-last format if enabled\n",
    "            if CONFIG['use_channels_last'] and torch.cuda.is_available():\n",
    "                try:\n",
    "                    data = data.to(memory_format=torch.channels_last)\n",
    "                except:\n",
    "                    pass  # Fallback silently\n",
    "            \n",
    "            # üöÄ Forward pass with mixed precision\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if scaler is not None:\n",
    "                # Mixed precision forward pass\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = compiled_model(data)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Mixed precision backward pass\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(compiled_model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard precision\n",
    "                outputs = compiled_model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(compiled_model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Track metrics and speed\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            # üöÄ Speed tracking\n",
    "            batch_end_time = time.time()\n",
    "            batch_time = batch_end_time - batch_iteration_start\n",
    "            batch_times.append(batch_time)\n",
    "            \n",
    "            samples_processed = targets.size(0)\n",
    "            current_speed = samples_processed / batch_time\n",
    "            samples_per_second.append(current_speed)\n",
    "            \n",
    "            # Calculate current metrics\n",
    "            current_acc = 100. * train_correct / train_total\n",
    "            avg_speed = np.mean(samples_per_second[-10:]) if len(samples_per_second) >= 10 else np.mean(samples_per_second)\n",
    "            \n",
    "            # Update progress bar with speed info\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%',\n",
    "                'Speed': f'{avg_speed:.1f}s/s',\n",
    "                'Batch': f'{batch_time*1000:.1f}ms'\n",
    "            })\n",
    "            \n",
    "            # Memory cleanup every 50 batches\n",
    "            if batch_idx % 50 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Validation and epoch completion\n",
    "        epoch_metrics = _run_validation_and_update(compiled_model, scaler, epoch, train_loss, \n",
    "                                                  train_correct, train_total, metrics, \n",
    "                                                  best_model_state, patience_counter,\n",
    "                                                  epoch_start_time, epoch_times, samples_per_second,\n",
    "                                                  epoch_pbar)\n",
    "        \n",
    "        if epoch_metrics is None:  # Early stopping or target achieved\n",
    "            break\n",
    "        \n",
    "        best_model_state, patience_counter = epoch_metrics\n",
    "        \n",
    "        # Memory cleanup between epochs\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return _finalize_ultra_training(metrics, best_model_state, compiled_model, \n",
    "                                   training_start_time, samples_per_second, epoch_times)\n",
    "\n",
    "def _run_validation_and_update(compiled_model, scaler, epoch, train_loss, train_correct, \n",
    "                              train_total, metrics, best_model_state, patience_counter,\n",
    "                              epoch_start_time, epoch_times, samples_per_second, epoch_pbar):\n",
    "    \"\"\"Ultra-fast validation with mixed precision and metric updates\"\"\"\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    epoch_train_loss = train_loss / len(train_loader)\n",
    "    epoch_train_acc = 100. * train_correct / train_total\n",
    "    \n",
    "    # üöÄ Ultra-fast validation with mixed precision\n",
    "    compiled_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(test_loader, desc='‚ö° Ultra-Fast Val', position=1, leave=False)\n",
    "        for data, targets in val_pbar:\n",
    "            if CONFIG['non_blocking']:\n",
    "                data = data.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "            else:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # Apply channels-last if enabled\n",
    "            if CONFIG['use_channels_last'] and torch.cuda.is_available():\n",
    "                try:\n",
    "                    data = data.to(memory_format=torch.channels_last)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Mixed precision inference\n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = compiled_model(data)\n",
    "                    loss = criterion(outputs, targets)\n",
    "            else:\n",
    "                outputs = compiled_model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += targets.size(0)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            current_val_acc = 100. * val_correct / val_total\n",
    "            val_pbar.set_postfix({'Acc': f'{current_val_acc:.2f}%'})\n",
    "    \n",
    "    epoch_val_loss = val_loss / len(test_loader)\n",
    "    epoch_val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(epoch_val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Track metrics\n",
    "    metrics.update(epoch_train_loss, epoch_train_acc, epoch_val_loss, epoch_val_acc, current_lr)\n",
    "    \n",
    "    # üöÄ Speed calculations\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "    total_samples = len(train_dataset) + len(test_dataset)\n",
    "    epoch_speed = total_samples / epoch_time\n",
    "    avg_epoch_speed = np.mean(epoch_times[-5:]) if len(epoch_times) >= 5 else np.mean(epoch_times)\n",
    "    \n",
    "    # Estimate remaining time\n",
    "    remaining_epochs = CONFIG['num_epochs'] - (epoch + 1)\n",
    "    estimated_time_remaining = remaining_epochs * avg_epoch_speed / 60  # minutes\n",
    "    \n",
    "    # Update epoch progress bar with ultra-detailed metrics\n",
    "    epoch_pbar.set_postfix({\n",
    "        'Train Acc': f'{epoch_train_acc:.2f}%',\n",
    "        'Val Acc': f'{epoch_val_acc:.2f}%',\n",
    "        'Best': f'{metrics.best_val_acc:.2f}%',\n",
    "        'Speed': f'{epoch_speed:.0f}s/s',\n",
    "        'ETA': f'{estimated_time_remaining:.1f}m'\n",
    "    })\n",
    "    \n",
    "    # Print ultra-detailed epoch summary\n",
    "    print(f\"\\n‚ö° ULTRA-FAST Epoch {epoch+1}/{CONFIG['num_epochs']} Summary:\")\n",
    "    print(f\"   üìà Train - Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.2f}%\")\n",
    "    print(f\"   üìä Val   - Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.2f}%\")\n",
    "    print(f\"   üèÜ Best  - Val Acc: {metrics.best_val_acc:.2f}% (epoch {metrics.best_epoch+1})\")\n",
    "    print(f\"   ‚ö° Speed - {epoch_speed:.0f} samples/sec, Epoch: {epoch_time:.1f}s\")\n",
    "    print(f\"   üïí ETA   - {estimated_time_remaining:.1f} minutes remaining\")\n",
    "    print(f\"   üîß LR    - {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model with enhanced info\n",
    "    if epoch_val_acc > metrics.best_val_acc:\n",
    "        metrics.best_val_acc = epoch_val_acc\n",
    "        metrics.best_epoch = epoch\n",
    "        best_model_state = compiled_model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save checkpoint with speed metrics\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': compiled_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "            'best_val_acc': epoch_val_acc,\n",
    "            'config': CONFIG,\n",
    "            'class_mapping': class_mapping,\n",
    "            'speed_metrics': {\n",
    "                'epoch_speed': epoch_speed,\n",
    "                'avg_samples_per_second': np.mean(samples_per_second[-100:]) if samples_per_second else 0\n",
    "            }\n",
    "        }, MODEL_SAVE_PATH)\n",
    "        \n",
    "        print(f\"   üíæ üöÄ NEW BEST MODEL SAVED! Val Acc: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Check if we've achieved the target\n",
    "        if epoch_val_acc >= 87.60:\n",
    "            print(f\"\\nüéâ üèÜ TARGET ACHIEVED! üèÜ üéâ\")\n",
    "            print(f\"Ultra-fast training reached {epoch_val_acc:.2f}% >= 87.60% benchmark!\")\n",
    "            return None  # Signal to stop training\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"   ‚è≥ Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"\\n‚èπÔ∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "            print(f\"Best validation accuracy: {metrics.best_val_acc:.2f}% (epoch {metrics.best_epoch+1})\")\n",
    "            return None  # Signal to stop training\n",
    "    \n",
    "    # Stop if learning rate becomes too small\n",
    "    if current_lr < CONFIG['min_lr']:\n",
    "        print(f\"\\n‚èπÔ∏è Learning rate too small ({current_lr:.2e}), stopping training\")\n",
    "        return None  # Signal to stop training\n",
    "    \n",
    "    return best_model_state, patience_counter\n",
    "\n",
    "def _finalize_ultra_training(metrics, best_model_state, compiled_model, training_start_time, \n",
    "                           samples_per_second, epoch_times):\n",
    "    \"\"\"Finalize ultra-optimized training with results and analysis\"\"\"\n",
    "    \n",
    "    total_time = time.time() - training_start_time\n",
    "    \n",
    "    print(f\"\\nüèÅ üöÄ ULTRA-FAST TRAINING COMPLETE! üöÄ üèÅ\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"‚è±Ô∏è  Total time: {total_time/3600:.2f} hours ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"üèÜ Best validation accuracy: {metrics.best_val_acc:.2f}% (epoch {metrics.best_epoch+1})\")\n",
    "    print(f\"üéØ Literature benchmark: 87.60%\")\n",
    "    print(f\"‚ö° Average speed: {np.mean(samples_per_second):.0f} samples/second\")\n",
    "    print(f\"üî• Average epoch time: {np.mean(epoch_times):.1f} seconds\")\n",
    "    \n",
    "    # Performance analysis\n",
    "    if metrics.best_val_acc >= 87.60:\n",
    "        print(f\"üéâ üéâ üéâ SUCCESS! BENCHMARK ACHIEVED! üéâ üéâ üéâ\")\n",
    "        print(f\"Ultra-optimized training achieved {metrics.best_val_acc:.2f}% >= 87.60%!\")\n",
    "    elif metrics.best_val_acc >= 85.0:\n",
    "        print(f\"üî• üî• EXCELLENT! Very close to benchmark! üî• üî•\")\n",
    "        print(f\"Achieved {metrics.best_val_acc:.2f}% - only {87.60 - metrics.best_val_acc:.2f}% away!\")\n",
    "    elif metrics.best_val_acc >= 80.0:\n",
    "        print(f\"‚úÖ ‚úÖ GREAT! Strong performance! ‚úÖ ‚úÖ\")\n",
    "    else:\n",
    "        print(f\"üìà Good progress! Consider hyperparameter tuning.\")\n",
    "    \n",
    "    # Speed analysis\n",
    "    if samples_per_second and epoch_times:\n",
    "        print(f\"\\n‚ö° SPEED ANALYSIS:\")\n",
    "        print(f\"   üöÄ Peak speed: {max(samples_per_second):.0f} samples/second\")\n",
    "        print(f\"   üìä Average speed: {np.mean(samples_per_second):.0f} samples/second\")\n",
    "        print(f\"   üî• Fastest epoch: {min(epoch_times):.1f} seconds\")\n",
    "        print(f\"   ‚ö° Total speedup: ~{len(samples_per_second) * np.mean(samples_per_second) / max(1, total_time):.1f}x\")\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        compiled_model.load_state_dict(best_model_state)\n",
    "        print(f\"‚úÖ Best model restored for evaluation\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    print(\"\\nüìà Plotting ultra-fast training metrics...\")\n",
    "    metrics.plot_metrics()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91fae8",
   "metadata": {},
   "source": [
    "## üöÄ Execute Ultra-Optimized Training\n",
    "\n",
    "Run the complete ultra-optimized training pipeline with all GPU enhancements enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61781848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ultra_optimized():\n",
    "    \"\"\"Ultra-optimized training function with all GPU enhancements\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting ultra-fast training with GPU optimizations...\")\n",
    "    print(\"üî• Features: Mixed Precision + Model Compilation + Speed Tracking\")\n",
    "    print(f\"üìä Dataset: {len(train_dataset)} train, {len(test_dataset)} test\")\n",
    "    print(f\"üéØ Classes: {train_dataset.num_classes}\")\n",
    "    print(f\"üèóÔ∏è Model: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    print(f\"‚öôÔ∏è Device: {device}\")\n",
    "    print(f\"üéØ Target: 87.60% accuracy (WLASL-100 benchmark)\")\n",
    "    \n",
    "    # Initialize training components\n",
    "    try:\n",
    "        # Enable optimizations\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Initialize mixed precision scaler\n",
    "        scaler = GradScaler() if CONFIG['use_mixed_precision'] and torch.cuda.is_available() else None\n",
    "        \n",
    "        # Compile model for PyTorch 2.0+ optimizations\n",
    "        compilation_successful = False\n",
    "        if CONFIG['compile_model']:\n",
    "            try:\n",
    "                compiled_model = torch.compile(model, mode='reduce-overhead')\n",
    "                compilation_successful = True\n",
    "                print(\"‚úÖ Model compilation successful!\")\n",
    "            except Exception as e:\n",
    "                compiled_model = model\n",
    "                print(f\"‚ö†Ô∏è Model compilation failed: {e}\")\n",
    "                print(\"   Falling back to regular model\")\n",
    "        else:\n",
    "            compiled_model = model\n",
    "            print(\"‚ÑπÔ∏è Model compilation disabled in config\")\n",
    "        \n",
    "        # Initialize metrics tracker\n",
    "        metrics = MetricsTracker()\n",
    "        \n",
    "        # Training variables\n",
    "        best_model_state = None\n",
    "        patience_counter = 0\n",
    "        training_start_time = time.time()\n",
    "        batch_times = []\n",
    "        epoch_times = []\n",
    "        samples_per_second = []\n",
    "        \n",
    "        print(\"\\nüöÄ Starting ultra-optimized training loop...\")\n",
    "        \n",
    "        # Execute the core training loop\n",
    "        result = _run_ultra_training_loop(\n",
    "            compiled_model, scaler, metrics, best_model_state,\n",
    "            patience_counter, training_start_time, batch_times,\n",
    "            epoch_times, samples_per_second\n",
    "        )\n",
    "        \n",
    "        if result is not None:\n",
    "            best_model_state, patience_counter = result\n",
    "        \n",
    "        # Finalize training\n",
    "        final_metrics = _finalize_ultra_training(\n",
    "            metrics, best_model_state, compiled_model, training_start_time,\n",
    "            samples_per_second, epoch_times\n",
    "        )\n",
    "        \n",
    "        return final_metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed with error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f1b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING ULTRA-OPTIMIZED TGCN TRAINING üöÄ\n",
      "======================================================================\n",
      "üìä Dataset: 135 train, 34 test samples\n",
      "üéØ Classes: 10\n",
      "üèóÔ∏è Model: 117,730 parameters\n",
      "‚öôÔ∏è Device: cuda\n",
      "üéØ Target: 87.60% accuracy (WLASL-100 benchmark)\n",
      "\n",
      "======================================================================\n",
      "üöÄ Starting ultra-fast training with GPU optimizations...\n",
      "üî• Features: Mixed Precision + Model Compilation + Speed Tracking\n",
      "üìä Dataset: 135 train, 34 test\n",
      "üéØ Classes: 10\n",
      "üèóÔ∏è Model: 117,730 parameters\n",
      "‚öôÔ∏è Device: cuda\n",
      "üéØ Target: 87.60% accuracy (WLASL-100 benchmark)\n",
      "‚ÑπÔ∏è Model compilation disabled in config\n",
      "\n",
      "üöÄ Starting ultra-optimized training loop...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8040a040e8bd4c11b5f47152b8449c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Ultra-Fast Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612daad7bca24769b3d25c882995bab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Epoch 1/50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785617c1ac3a4799bd4a92ab0447db1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Ultra-Fast Val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° ULTRA-FAST Epoch 1/50 Summary:\n",
      "   üìà Train - Loss: 2.5620, Acc: 9.63%\n",
      "   üìä Val   - Loss: 2.2970, Acc: 14.71%\n",
      "   üèÜ Best  - Val Acc: 14.71% (epoch 1)\n",
      "   ‚ö° Speed - 7 samples/sec, Epoch: 22.7s\n",
      "   üïí ETA   - 18.5 minutes remaining\n",
      "   üîß LR    - 0.002000\n",
      "   ‚è≥ Patience: 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accc4e9361bd4d4db29ff7720be8a6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Epoch 2/50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088214346dad4f10a859502d971f69ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Ultra-Fast Val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° ULTRA-FAST Epoch 2/50 Summary:\n",
      "   üìà Train - Loss: 2.3577, Acc: 11.11%\n",
      "   üìä Val   - Loss: 2.2981, Acc: 11.76%\n",
      "   üèÜ Best  - Val Acc: 14.71% (epoch 1)\n",
      "   ‚ö° Speed - 8 samples/sec, Epoch: 22.2s\n",
      "   üïí ETA   - 18.0 minutes remaining\n",
      "   üîß LR    - 0.002000\n",
      "   ‚è≥ Patience: 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed4f8638aa5450a8e327f24778dbb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Epoch 3/50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07603f37eeb487ea2d8816234ae56df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Ultra-Fast Val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° ULTRA-FAST Epoch 3/50 Summary:\n",
      "   üìà Train - Loss: 2.2906, Acc: 9.63%\n",
      "   üìä Val   - Loss: 2.3107, Acc: 14.71%\n",
      "   üèÜ Best  - Val Acc: 14.71% (epoch 1)\n",
      "   ‚ö° Speed - 8 samples/sec, Epoch: 22.3s\n",
      "   üïí ETA   - 17.6 minutes remaining\n",
      "   üîß LR    - 0.002000\n",
      "   ‚è≥ Patience: 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e92d39dce4f4df892538720182784f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Epoch 4/50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbd0910beb4463abdc6c85e708889ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Ultra-Fast Val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° ULTRA-FAST Epoch 4/50 Summary:\n",
      "   üìà Train - Loss: 2.3114, Acc: 11.11%\n",
      "   üìä Val   - Loss: 2.3036, Acc: 11.76%\n",
      "   üèÜ Best  - Val Acc: 14.71% (epoch 1)\n",
      "   ‚ö° Speed - 8 samples/sec, Epoch: 21.8s\n",
      "   üïí ETA   - 17.1 minutes remaining\n",
      "   üîß LR    - 0.002000\n",
      "   ‚è≥ Patience: 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dbb7829b06491c98e7c93566988d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Epoch 5/50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd2239a8f854c2faf06b771923ca152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Ultra-Fast Val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° ULTRA-FAST Epoch 5/50 Summary:\n",
      "   üìà Train - Loss: 2.2977, Acc: 13.33%\n",
      "   üìä Val   - Loss: 2.2972, Acc: 14.71%\n",
      "   üèÜ Best  - Val Acc: 14.71% (epoch 1)\n",
      "   ‚ö° Speed - 8 samples/sec, Epoch: 21.6s\n",
      "   üïí ETA   - 16.6 minutes remaining\n",
      "   üîß LR    - 0.002000\n",
      "   ‚è≥ Patience: 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14dbe88d651461a9ef31821ccaf2026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Epoch 6/50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65511d06d505405f81dbc157b6f92524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Ultra-Fast Val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° ULTRA-FAST Epoch 6/50 Summary:\n",
      "   üìà Train - Loss: 2.3020, Acc: 6.67%\n",
      "   üìä Val   - Loss: 2.2919, Acc: 14.71%\n",
      "   üèÜ Best  - Val Acc: 14.71% (epoch 1)\n",
      "   ‚ö° Speed - 6 samples/sec, Epoch: 26.3s\n",
      "   üïí ETA   - 16.8 minutes remaining\n",
      "   üîß LR    - 0.002000\n",
      "   ‚è≥ Patience: 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df08ccf80c2b428790a29cc4c4720631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "‚ö° Epoch 7/50:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if data_ready:\n",
    "    print(\"üöÄ STARTING ULTRA-OPTIMIZED TGCN TRAINING üöÄ\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìä Dataset: {len(train_dataset)} train, {len(test_dataset)} test samples\")\n",
    "    print(f\"üéØ Classes: {train_dataset.num_classes}\")\n",
    "    print(f\"üèóÔ∏è Model: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    print(f\"‚öôÔ∏è Device: {device}\")\n",
    "    print(f\"üéØ Target: 87.60% accuracy (WLASL-100 benchmark)\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Start ultra-optimized training\n",
    "    training_metrics = train_model_ultra_optimized()\n",
    "    \n",
    "    if training_metrics:\n",
    "        print(f\"\\nüèÜ ULTRA-FAST Training Results:\")\n",
    "        print(f\"   üéØ Best Accuracy: {training_metrics.best_val_acc:.2f}%\")\n",
    "        print(f\"   üìÖ Best Epoch: {training_metrics.best_epoch + 1}\")\n",
    "        print(f\"   üíæ Model saved: {MODEL_SAVE_PATH}\")\n",
    "        \n",
    "        # Show final comparison\n",
    "        if training_metrics.best_val_acc >= 87.60:\n",
    "            print(f\"\\nüéâ üéâ üéâ SUCCESS! üéâ üéâ üéâ\")\n",
    "            print(f\"BENCHMARK ACHIEVED: {training_metrics.best_val_acc:.2f}% >= 87.60%!\")\n",
    "            print(f\"üöÄ Ultra-optimized training was successful!\")\n",
    "        elif training_metrics.best_val_acc >= 85.0:\n",
    "            print(f\"\\nüî• EXCELLENT! Very close to benchmark!\")\n",
    "            print(f\"Achieved {training_metrics.best_val_acc:.2f}% - only {87.60 - training_metrics.best_val_acc:.2f}% away!\")\n",
    "        elif training_metrics.best_val_acc >= 80.0:\n",
    "            print(f\"\\n‚úÖ GREAT! Strong performance achieved!\")\n",
    "        else:\n",
    "            print(f\"\\nüìà Good progress! Consider hyperparameter tuning.\")\n",
    "    \n",
    "    # Save training metrics\n",
    "    training_results = {\n",
    "        'best_val_acc': training_metrics.best_val_acc,\n",
    "        'best_epoch': training_metrics.best_epoch,\n",
    "        'total_epochs': len(training_metrics.val_accuracies),\n",
    "        'final_train_acc': training_metrics.train_accuracies[-1] if training_metrics.train_accuracies else 0,\n",
    "        'config': CONFIG,\n",
    "        'timestamp': time.strftime('%Y%m%d_%H%M%S')\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(CHECKPOINT_DIR, 'training_results.json'), 'w') as f:\n",
    "        json.dump(training_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Training results saved to: {CHECKPOINT_DIR}/training_results.json\")\n",
    "    print(f\"Model saved to: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot start training. Please fix data issues first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c68db",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation and Analysis\n",
    "\n",
    "Evaluate the trained model and analyze its performance in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c08bd",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation and Analysis\n",
    "\n",
    "Evaluate the trained model and analyze its performance in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c244f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, class_mapping, device):\n",
    "    \"\"\"Comprehensive model evaluation with detailed metrics\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    print(\"üîç Evaluating model on test set...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm(test_loader, desc='Evaluation')\n",
    "        for data, targets in test_pbar:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_names = [class_mapping['idx_to_word'][str(i)] for i in range(len(class_mapping['idx_to_word']))]\n",
    "    report = classification_report(all_targets, all_predictions, \n",
    "                                 target_names=class_names, \n",
    "                                 output_dict=True, zero_division=0)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "    \n",
    "    print(f\"\\nüìä Evaluation Results:\")\n",
    "    print(f\"  Overall Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"  Macro Avg F1-Score: {report['macro avg']['f1-score']:.3f}\")\n",
    "    print(f\"  Weighted Avg F1-Score: {report['weighted avg']['f1-score']:.3f}\")\n",
    "    \n",
    "    # Per-class analysis\n",
    "    print(f\"\\nüìã Per-Class Performance:\")\n",
    "    class_accuracies = []\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if str(i) in report and isinstance(report[str(i)], dict):\n",
    "            precision = report[str(i)]['precision']\n",
    "            recall = report[str(i)]['recall']\n",
    "            f1 = report[str(i)]['f1-score']\n",
    "            support = report[str(i)]['support']\n",
    "            \n",
    "            # Calculate per-class accuracy\n",
    "            class_mask = np.array(all_targets) == i\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_acc = accuracy_score(\n",
    "                    np.array(all_targets)[class_mask],\n",
    "                    np.array(all_predictions)[class_mask]\n",
    "                )\n",
    "                class_accuracies.append((class_name, class_acc, np.sum(class_mask)))\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    class_accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Top 10 Best Performing Classes:\")\n",
    "    for name, acc, count in class_accuracies[:10]:\n",
    "        print(f\"  {name}: {acc*100:.1f}% ({count} samples)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Bottom 10 Performing Classes:\")\n",
    "    for name, acc, count in class_accuracies[-10:]:\n",
    "        print(f\"  {name}: {acc*100:.1f}% ({count} samples)\")\n",
    "    \n",
    "    return accuracy, report, cm\n",
    "\n",
    "if data_ready and os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(\"üîÑ Loading best model for evaluation...\")\n",
    "    \n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded from epoch {checkpoint['epoch']+1}\")\n",
    "    print(f\"Best validation accuracy: {checkpoint['best_val_acc']:.2f}%\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy, report, cm = evaluate_model(model, test_loader, class_mapping, device)\n",
    "    \n",
    "    # Compare with literature\n",
    "    print(f\"\\nüèÜ Performance Comparison:\")\n",
    "    print(f\"Our Model: {accuracy*100:.2f}%\")\n",
    "    print(f\"Literature Benchmark (WLASL-100): 87.60%\")\n",
    "    \n",
    "    if accuracy*100 >= 87.60:\n",
    "        print(f\"üéâ SUCCESS! We've achieved the literature benchmark!\")\n",
    "    elif accuracy*100 >= 80.0:\n",
    "        print(f\"‚úÖ GOOD! Strong performance, close to benchmark\")\n",
    "    elif accuracy*100 >= 70.0:\n",
    "        print(f\"‚ö†Ô∏è MODERATE: Decent performance, room for improvement\")\n",
    "    else:\n",
    "        print(f\"‚ùå POOR: Significant improvement needed\")\n",
    "    \n",
    "    # Save evaluation results\n",
    "    evaluation_results = {\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'model_path': MODEL_SAVE_PATH,\n",
    "        'timestamp': time.strftime('%Y%m%d_%H%M%S')\n",
    "    }\n",
    "    \n",
    "    eval_path = os.path.join(CHECKPOINT_DIR, 'evaluation_results.json')\n",
    "    with open(eval_path, 'w') as f:\n",
    "        json.dump(evaluation_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nüíæ Evaluation results saved to: {eval_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Model not found. Please train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39745000",
   "metadata": {},
   "source": [
    "## üéØ Training Summary and Next Steps\n",
    "\n",
    "Final summary of the ultra-optimized TGCN training results and recommendations for next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7639c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ ULTRA-OPTIMIZED TGCN TRAINING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if data_ready and os.path.exists(MODEL_SAVE_PATH):\n",
    "    # Load final results\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH, map_location='cpu')\n",
    "    final_accuracy = checkpoint.get('best_val_acc', 0)\n",
    "    \n",
    "    print(f\"üìä Final Results:\")\n",
    "    print(f\"   üéØ Best Validation Accuracy: {final_accuracy:.2f}%\")\n",
    "    print(f\"   üìà Target Benchmark: 87.60%\")\n",
    "    print(f\"   üìÅ Model saved at: {MODEL_SAVE_PATH}\")\n",
    "    \n",
    "    # Performance assessment\n",
    "    if final_accuracy >= 87.60:\n",
    "        print(f\"\\nüéâ üèÜ OUTSTANDING SUCCESS! üèÜ üéâ\")\n",
    "        print(f\"‚úÖ Achieved benchmark: {final_accuracy:.2f}% >= 87.60%\")\n",
    "        print(f\"üöÄ Ultra-optimized training was highly effective!\")\n",
    "        status = \"SUCCESS\"\n",
    "    elif final_accuracy >= 85.0:\n",
    "        print(f\"\\nüî• EXCELLENT PERFORMANCE! üî•\")\n",
    "        print(f\"‚úÖ Very close to benchmark: {final_accuracy:.2f}%\")\n",
    "        print(f\"üìà Gap: {87.60 - final_accuracy:.2f}%\")\n",
    "        status = \"EXCELLENT\"\n",
    "    elif final_accuracy >= 80.0:\n",
    "        print(f\"\\n‚úÖ GOOD PERFORMANCE!\")\n",
    "        print(f\"üìä Achieved: {final_accuracy:.2f}%\")\n",
    "        print(f\"üìà Gap: {87.60 - final_accuracy:.2f}%\")\n",
    "        status = \"GOOD\"\n",
    "    elif final_accuracy >= 70.0:\n",
    "        print(f\"\\n‚ö†Ô∏è MODERATE PERFORMANCE\")\n",
    "        print(f\"üìä Achieved: {final_accuracy:.2f}%\")\n",
    "        print(f\"üìà Needs improvement: {87.60 - final_accuracy:.2f}%\")\n",
    "        status = \"MODERATE\"\n",
    "    else:\n",
    "        print(f\"\\n‚ùå POOR PERFORMANCE\")\n",
    "        print(f\"üìä Achieved: {final_accuracy:.2f}%\")\n",
    "        print(f\"üîß Significant improvements needed\")\n",
    "        status = \"POOR\"\n",
    "    \n",
    "    print(f\"\\nüöÄ Optimization Features Used:\")\n",
    "    print(f\"   ‚úÖ Mixed Precision Training (AMP)\")\n",
    "    print(f\"   ‚úÖ PyTorch 2.0 Model Compilation\")\n",
    "    print(f\"   ‚úÖ cuDNN Optimizations\")\n",
    "    print(f\"   ‚úÖ Memory Layout Optimization\")\n",
    "    print(f\"   ‚úÖ Async GPU Transfers\")\n",
    "    print(f\"   ‚úÖ Gradient Clipping & Scaling\")\n",
    "    print(f\"   ‚úÖ Early Stopping & LR Scheduling\")\n",
    "    print(f\"   ‚úÖ Data Augmentation\")\n",
    "    \n",
    "    print(f\"\\nüìã Next Steps Based on Performance:\")\n",
    "    \n",
    "    if status == \"SUCCESS\":\n",
    "        print(f\"   üéØ Model is ready for deployment!\")\n",
    "        print(f\"   üìä Consider inference optimization\")\n",
    "        print(f\"   üîÑ Test on additional datasets\")\n",
    "        print(f\"   üìù Document deployment procedures\")\n",
    "    \n",
    "    elif status in [\"EXCELLENT\", \"GOOD\"]:\n",
    "        print(f\"   üîß Fine-tune hyperparameters:\")\n",
    "        print(f\"      - Increase model capacity (gcn_hidden: 256+)\")\n",
    "        print(f\"      - More training epochs with lower learning rate\")\n",
    "        print(f\"      - Stronger data augmentation\")\n",
    "        print(f\"   üìä Ensemble methods\")\n",
    "        print(f\"   üéØ Test different architectures\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"   üîß Major improvements needed:\")\n",
    "        print(f\"      - Check data quality and preprocessing\")\n",
    "        print(f\"      - Increase model complexity\")\n",
    "        print(f\"      - More training data\")\n",
    "        print(f\"      - Learning rate scheduling\")\n",
    "        print(f\"   üìä Consider different model architectures\")\n",
    "        print(f\"   üêõ Debug training pipeline\")\n",
    "    \n",
    "    print(f\"\\nüíæ Files Generated:\")\n",
    "    print(f\"   üîπ Model: {MODEL_SAVE_PATH}\")\n",
    "    print(f\"   üîπ Class mapping: {CHECKPOINT_DIR}/class_mapping.json\")\n",
    "    print(f\"   üîπ Training results: {CHECKPOINT_DIR}/training_results.json\")\n",
    "    if os.path.exists(os.path.join(CHECKPOINT_DIR, 'evaluation_results.json')):\n",
    "        print(f\"   üîπ Evaluation: {CHECKPOINT_DIR}/evaluation_results.json\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùå Training incomplete or failed.\")\n",
    "    print(f\"üìã Troubleshooting steps:\")\n",
    "    print(f\"   1. Check data directory: {DATA_DIR}\")\n",
    "    print(f\"   2. Verify keypoint extraction\")\n",
    "    print(f\"   3. Check GPU memory and CUDA\")\n",
    "    print(f\"   4. Review error messages above\")\n",
    "\n",
    "print(f\"\\nüéâ Ultra-Optimized TGCN Pipeline Complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aslpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
