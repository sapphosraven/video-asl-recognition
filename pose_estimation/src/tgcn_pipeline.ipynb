{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e010612b",
   "metadata": {},
   "source": [
    "# Temporal GCN Workflow for ASL Pose Sequences\n",
    "\n",
    "This notebook implements the full TGCN pipeline in self-contained phases:\n",
    "\n",
    "1. Core TGCN architecture\n",
    "2. Dataset loader & preprocessing\n",
    "3. Training loop with checkpoints\n",
    "4. Evaluation metrics & inference\n",
    "5. Hyperparameter tuning & optimization\n",
    "\n",
    "All intermediate models, logs, and results are saved to disk to prevent data loss if the notebook or IDE crashes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28687d9f",
   "metadata": {},
   "source": [
    "## Phase 1: Core TGCN Architecture\n",
    "\n",
    "Define graph convolution and temporal graph convolution layers using PyTorch and PyTorch Geometric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b93276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "from mediapipe.python.solutions import pose_connections, hands_connections\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Build static adjacency matrix (75x75) for MediaPipe pose + hands\n",
    "NUM_POSE, NUM_HAND = 33, 21\n",
    "TOTAL_NODES = NUM_POSE + 2 * NUM_HAND\n",
    "\n",
    "# Get connections from MediaPipe\n",
    "POSE_CONNECTIONS = pose_connections.POSE_CONNECTIONS\n",
    "HAND_CONNECTIONS = hands_connections.HAND_CONNECTIONS\n",
    "\n",
    "# Build edge list\n",
    "edges = set()\n",
    "# Pose connections (0-32)\n",
    "for u, v in POSE_CONNECTIONS:\n",
    "    edges.add((u, v))\n",
    "    edges.add((v, u))\n",
    "\n",
    "# Left hand connections (33-53)\n",
    "off1 = NUM_POSE\n",
    "for u, v in HAND_CONNECTIONS:\n",
    "    edges.add((off1 + u, off1 + v))\n",
    "    edges.add((off1 + v, off1 + u))\n",
    "\n",
    "# Right hand connections (54-74)\n",
    "off2 = NUM_POSE + NUM_HAND\n",
    "for u, v in HAND_CONNECTIONS:\n",
    "    edges.add((off2 + u, off2 + v))\n",
    "    edges.add((off2 + v, off2 + u))\n",
    "\n",
    "# Convert to edge_index format for PyTorch Geometric\n",
    "edge_list = list(edges)\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "print(f\"Graph structure: {TOTAL_NODES} nodes, {len(edge_list)} edges\")\n",
    "print(f\"Edge index shape: {edge_index.shape}\")\n",
    "\n",
    "class TGCNLayer(nn.Module):\n",
    "    \"\"\"Temporal Graph Convolutional Layer\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, K=3):\n",
    "        super(TGCNLayer, self).__init__()\n",
    "        self.K = K\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # Graph convolution\n",
    "        self.gcn = GCNConv(in_channels, out_channels)\n",
    "        \n",
    "        # Temporal convolution (1D conv over time dimension)\n",
    "        self.temporal_conv = nn.Conv1d(out_channels, out_channels, kernel_size=K, padding=K//2)\n",
    "        \n",
    "        # Normalization and activation\n",
    "        self.batch_norm = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size * seq_len, num_nodes, in_channels]\n",
    "            edge_index: [2, num_edges]\n",
    "        Returns:\n",
    "            x: [batch_size * seq_len, num_nodes, out_channels]\n",
    "        \"\"\"\n",
    "        batch_seq, num_nodes, _ = x.shape\n",
    "        \n",
    "        # Apply graph convolution\n",
    "        x_flat = x.view(-1, self.in_channels)  # [batch_seq * num_nodes, in_channels]\n",
    "        \n",
    "        # Create expanded edge_index for batched graphs\n",
    "        batch_size = batch_seq\n",
    "        edge_indices = []\n",
    "        for i in range(batch_size):\n",
    "            edge_idx = edge_index + i * num_nodes\n",
    "            edge_indices.append(edge_idx)\n",
    "        \n",
    "        edge_index_batch = torch.cat(edge_indices, dim=1)\n",
    "        \n",
    "        # Apply GCN\n",
    "        x_gcn = self.gcn(x_flat, edge_index_batch)  # [batch_seq * num_nodes, out_channels]\n",
    "        x_gcn = x_gcn.view(batch_seq, num_nodes, self.out_channels)\n",
    "        \n",
    "        # Apply temporal convolution over sequence dimension\n",
    "        # Reshape for temporal conv: [batch, channels, sequence]\n",
    "        x_temp = x_gcn.permute(1, 2, 0)  # [num_nodes, out_channels, batch_seq]\n",
    "        \n",
    "        # Apply temporal conv to each node independently\n",
    "        x_out = []\n",
    "        for node_idx in range(num_nodes):\n",
    "            node_features = x_temp[node_idx]  # [out_channels, batch_seq]\n",
    "            node_conv = self.temporal_conv(node_features.unsqueeze(0)).squeeze(0)\n",
    "            x_out.append(node_conv)\n",
    "        \n",
    "        x_out = torch.stack(x_out, dim=0)  # [num_nodes, out_channels, batch_seq]\n",
    "        x_out = x_out.permute(2, 0, 1)  # [batch_seq, num_nodes, out_channels]\n",
    "        \n",
    "        # Apply normalization and activation\n",
    "        x_out = x_out.permute(0, 2, 1)  # [batch_seq, out_channels, num_nodes]\n",
    "        x_out = self.batch_norm(x_out)\n",
    "        x_out = F.relu(x_out)\n",
    "        x_out = self.dropout(x_out)\n",
    "        x_out = x_out.permute(0, 2, 1)  # [batch_seq, num_nodes, out_channels]\n",
    "        \n",
    "        return x_out\n",
    "\n",
    "class TGCN(nn.Module):\n",
    "    \"\"\"Temporal Graph Convolutional Network for ASL Recognition\"\"\"\n",
    "    def __init__(self, num_nodes, in_features, hidden_dim, num_classes, num_layers=2, dropout=0.3):\n",
    "        super(TGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # TGCN layers\n",
    "        self.tgcn_layers = nn.ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.tgcn_layers.append(TGCNLayer(in_features, hidden_dim))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.tgcn_layers.append(TGCNLayer(hidden_dim, hidden_dim))\n",
    "        \n",
    "        # Global pooling and classification\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, num_nodes, in_features]\n",
    "            edge_index: [2, num_edges]\n",
    "        Returns:\n",
    "            output: [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, num_nodes, in_features = x.shape\n",
    "        \n",
    "        # Reshape for processing: [batch_size * seq_len, num_nodes, in_features]\n",
    "        x = x.view(batch_size * seq_len, num_nodes, in_features)\n",
    "        \n",
    "        # Apply TGCN layers\n",
    "        for layer in self.tgcn_layers:\n",
    "            x = layer(x, edge_index)\n",
    "        \n",
    "        # Reshape back: [batch_size, seq_len, num_nodes, hidden_dim]\n",
    "        x = x.view(batch_size, seq_len, num_nodes, -1)\n",
    "        \n",
    "        # Global pooling over nodes: [batch_size, seq_len, hidden_dim]\n",
    "        x = x.mean(dim=2)\n",
    "        \n",
    "        # Temporal pooling: [batch_size, hidden_dim, seq_len] -> [batch_size, hidden_dim, 1]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.global_pool(x).squeeze(-1)  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Classification\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test the model structure\n",
    "print(\"\\n=== TGCN Architecture Test ===\")\n",
    "model = TGCN(num_nodes=TOTAL_NODES, in_features=3, hidden_dim=64, num_classes=10)\n",
    "test_input = torch.randn(2, 50, TOTAL_NODES, 3)  # batch=2, seq=50, nodes=75, features=3\n",
    "test_output = model(test_input, edge_index)\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {test_output.shape}\")\n",
    "print(\"âœ“ TGCN architecture implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc04eda6",
   "metadata": {},
   "source": [
    "## Phase 2: Dataset Loader & Preprocessing\n",
    "\n",
    "Load NPZ keypoint sequences, pad/truncate to fixed length, and build PyTorch Geometric Data objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "class PoseSequenceDataset(Dataset):\n",
    "    \"\"\"Dataset for pose keypoint sequences from NPZ files\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, max_seq_len=80, split='train', test_size=0.2, random_state=42):\n",
    "        self.data_dir = data_dir\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.split = split\n",
    "        \n",
    "        # Find all NPZ files\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.word_to_idx = {}\n",
    "        self.idx_to_word = {}\n",
    "        \n",
    "        print(f\"Loading dataset from: {data_dir}\")\n",
    "        \n",
    "        # Scan directory structure\n",
    "        word_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "        print(f\"Found {len(word_dirs)} word categories\")\n",
    "        \n",
    "        # Build label mapping\n",
    "        for idx, word in enumerate(sorted(word_dirs)):\n",
    "            self.word_to_idx[word] = idx\n",
    "            self.idx_to_word[idx] = word\n",
    "        \n",
    "        self.num_classes = len(self.word_to_idx)\n",
    "        print(f\"Number of classes: {self.num_classes}\")\n",
    "        \n",
    "        # Collect all files with labels\n",
    "        file_label_pairs = []\n",
    "        for word, label_idx in self.word_to_idx.items():\n",
    "            word_dir = os.path.join(data_dir, word)\n",
    "            npz_files = glob.glob(os.path.join(word_dir, \"*.npz\"))\n",
    "            \n",
    "            for file_path in npz_files:\n",
    "                file_label_pairs.append((file_path, label_idx))\n",
    "        \n",
    "        print(f\"Total files found: {len(file_label_pairs)}\")\n",
    "        \n",
    "        if len(file_label_pairs) == 0:\n",
    "            raise ValueError(f\"No NPZ files found in {data_dir}\")\n",
    "        \n",
    "        # Split into train/test\n",
    "        files, labels = zip(*file_label_pairs)\n",
    "        \n",
    "        if len(files) > 1:\n",
    "            train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "                files, labels, test_size=test_size, random_state=random_state, stratify=labels\n",
    "            )\n",
    "        else:\n",
    "            # Edge case: only one file\n",
    "            train_files, test_files = files, files\n",
    "            train_labels, test_labels = labels, labels\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.files = list(train_files)\n",
    "            self.labels = list(train_labels)\n",
    "        else:\n",
    "            self.files = list(test_files)\n",
    "            self.labels = list(test_labels)\n",
    "        \n",
    "        print(f\"{split.upper()} split: {len(self.files)} files\")\n",
    "        \n",
    "        # Class distribution\n",
    "        class_counts = defaultdict(int)\n",
    "        for label in self.labels:\n",
    "            class_counts[self.idx_to_word[label]] += 1\n",
    "        \n",
    "        print(f\"Class distribution in {split}:\")\n",
    "        for word, count in sorted(class_counts.items()):\n",
    "            print(f\"  {word}: {count} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load NPZ file\n",
    "            data = np.load(file_path)\n",
    "            \n",
    "            # Handle different possible keys\n",
    "            if 'keypoints' in data:\n",
    "                keypoints = data['keypoints']  # Shape: (seq_len, num_nodes, 3)\n",
    "            elif 'pose_keypoints' in data:\n",
    "                keypoints = data['pose_keypoints']\n",
    "            elif 'nodes' in data:\n",
    "                keypoints = data['nodes']\n",
    "            else:\n",
    "                # Try to find any array that looks like keypoints\n",
    "                arrays = [key for key in data.keys() if len(data[key].shape) == 3]\n",
    "                if arrays:\n",
    "                    keypoints = data[arrays[0]]\n",
    "                else:\n",
    "                    raise ValueError(f\"No suitable keypoint data found in {file_path}\")\n",
    "            \n",
    "            # Ensure proper shape\n",
    "            if len(keypoints.shape) == 3:\n",
    "                seq_len, num_nodes, num_features = keypoints.shape\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid keypoint shape: {keypoints.shape}\")\n",
    "            \n",
    "            # Handle sequence length\n",
    "            if seq_len > self.max_seq_len:\n",
    "                # Downsample sequence\n",
    "                indices = np.linspace(0, seq_len - 1, self.max_seq_len, dtype=int)\n",
    "                keypoints = keypoints[indices]\n",
    "            elif seq_len < self.max_seq_len:\n",
    "                # Pad sequence\n",
    "                padding = np.zeros((self.max_seq_len - seq_len, num_nodes, num_features))\n",
    "                keypoints = np.concatenate([keypoints, padding], axis=0)\n",
    "            \n",
    "            # Normalize keypoints to [-1, 1] range\n",
    "            keypoints = keypoints.astype(np.float32)\n",
    "            \n",
    "            # Remove NaN values\n",
    "            keypoints = np.nan_to_num(keypoints, nan=0.0)\n",
    "            \n",
    "            # Basic normalization (optional - can be improved)\n",
    "            keypoints = np.clip(keypoints, -2.0, 2.0)\n",
    "            \n",
    "            return torch.tensor(keypoints, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            # Return zero tensor as fallback\n",
    "            zero_keypoints = torch.zeros((self.max_seq_len, TOTAL_NODES, 3), dtype=torch.float32)\n",
    "            return zero_keypoints, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Load datasets\n",
    "data_dir = r\"f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints\"\n",
    "\n",
    "print(\"\\n=== Loading Datasets ===\")\n",
    "train_dataset = PoseSequenceDataset(data_dir, max_seq_len=80, split='train', test_size=0.2)\n",
    "val_dataset = PoseSequenceDataset(data_dir, max_seq_len=80, split='val', test_size=0.2)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8  # Start with smaller batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Test data loading\n",
    "print(\"\\n=== Testing Data Loading ===\")\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    sample_x, sample_y = sample_batch\n",
    "    print(f\"Sample batch shape: {sample_x.shape}\")  # Should be [batch_size, seq_len, nodes, features]\n",
    "    print(f\"Sample labels shape: {sample_y.shape}\")  # Should be [batch_size]\n",
    "    print(f\"Label range: {sample_y.min().item()} - {sample_y.max().item()}\")\n",
    "    print(f\"Keypoint value range: {sample_x.min().item():.3f} - {sample_x.max().item():.3f}\")\n",
    "    print(\"âœ“ Data loading successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Data loading failed: {e}\")\n",
    "\n",
    "# Save label mappings\n",
    "label_mapping = {\n",
    "    'word_to_idx': train_dataset.word_to_idx,\n",
    "    'idx_to_word': train_dataset.idx_to_word,\n",
    "    'num_classes': train_dataset.num_classes\n",
    "}\n",
    "\n",
    "with open('label_mapping.json', 'w') as f:\n",
    "    json.dump(label_mapping, f, indent=2)\n",
    "\n",
    "print(f\"\\nLabel mapping saved. Number of classes: {train_dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30bd6f",
   "metadata": {},
   "source": [
    "## Phase 3: Training Loop with Checkpoints\n",
    "\n",
    "Implement training & validation loops, saving model checkpoints at each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model parameters\n",
    "hidden_dim = 128\n",
    "num_classes = train_dataset.num_classes\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "patience = 10  # Early stopping patience\n",
    "\n",
    "# Initialize model\n",
    "model = TGCN(\n",
    "    num_nodes=TOTAL_NODES,\n",
    "    in_features=3,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    num_layers=3,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nModel initialized:\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Move edge_index to device\n",
    "edge_index_device = edge_index.to(device)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "# Early stopping variables\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "best_model_path = 'best_tgcn_model.pt'\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    \"\"\"Calculate accuracy from model outputs and true labels\"\"\"\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, edge_index):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data, edge_index)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        acc = calculate_accuracy(outputs, labels)\n",
    "        total_correct += acc * labels.size(0)\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'  Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}, Acc: {acc:.4f}')\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device, edge_index):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(data, edge_index)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            acc = calculate_accuracy(outputs, labels)\n",
    "            total_correct += acc * labels.size(0)\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_acc = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\n=== Starting Training ===\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "    print(\"Training...\")\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, edge_index_device)\n",
    "    \n",
    "    # Validation\n",
    "    print(\"Validating...\")\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device, edge_index_device)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch results\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch {epoch} Results:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "    print(f\"  Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    # Save checkpoint every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        checkpoint_path = f'tgcn_checkpoint_epoch_{epoch}.pt'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'history': history\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    # Early stopping and best model saving\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'model_config': {\n",
    "                'num_nodes': TOTAL_NODES,\n",
    "                'in_features': 3,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'num_classes': num_classes,\n",
    "                'num_layers': 3,\n",
    "                'dropout': 0.3\n",
    "            }\n",
    "        }, best_model_path)\n",
    "        print(f\"  âœ“ New best model saved! Val Acc: {val_acc:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  No improvement. Patience: {patience_counter}/{patience}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch} epochs\")\n",
    "        print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "        break\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n=== Training Completed ===\")\n",
    "print(f\"Total time: {total_time/60:.2f} minutes\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Best model saved as: {best_model_path}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Learning rate plot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['lr'], label='Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34d8e8",
   "metadata": {},
   "source": [
    "## Phase 4: Evaluation & Inference\n",
    "\n",
    "Compute accuracy, F1-score, and confusion matrix on validation/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the best model\n",
    "print(\"=== Model Evaluation ===\")\n",
    "print(\"Loading best model...\")\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model_config = checkpoint['model_config']\n",
    "\n",
    "# Recreate model with saved configuration\n",
    "eval_model = TGCN(\n",
    "    num_nodes=model_config['num_nodes'],\n",
    "    in_features=model_config['in_features'],\n",
    "    hidden_dim=model_config['hidden_dim'],\n",
    "    num_classes=model_config['num_classes'],\n",
    "    num_layers=model_config['num_layers'],\n",
    "    dropout=model_config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Load trained weights\n",
    "eval_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "eval_model.eval()\n",
    "\n",
    "print(f\"Model loaded from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['val_acc']:.4f}\")\n",
    "\n",
    "def evaluate_model(model, data_loader, device, edge_index, dataset_name=\"Test\"):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(f\"\\nEvaluating on {dataset_name} set...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels) in enumerate(data_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data, edge_index)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store results\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 20 == 0:\n",
    "                print(f\"  Processed {batch_idx}/{len(data_loader)} batches\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "    f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"  F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "    print(f\"  Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probabilities,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'loss': avg_loss\n",
    "    }\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_results = evaluate_model(eval_model, val_loader, device, edge_index_device, \"Validation\")\n",
    "\n",
    "# Evaluate on training set (subset for speed)\n",
    "train_subset_size = min(len(train_loader), 50)  # Limit to 50 batches for speed\n",
    "train_subset_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(range(0, train_subset_size * batch_size))\n",
    ")\n",
    "train_results = evaluate_model(eval_model, train_subset_loader, device, edge_index_device, \"Training (subset)\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n=== Detailed Classification Report ===\")\n",
    "with open('label_mapping.json', 'r') as f:\n",
    "    label_mapping = json.load(f)\n",
    "\n",
    "idx_to_word = {int(k): v for k, v in label_mapping['idx_to_word'].items()}\n",
    "target_names = [idx_to_word[i] for i in range(len(idx_to_word))]\n",
    "\n",
    "print(\"\\nValidation Set Classification Report:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e901d46",
   "metadata": {},
   "source": [
    "## Phase 5: Hyperparameter Tuning (Optuna Stub)\n",
    "\n",
    "Outline hyperparameter search and early stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # stub: implement search over hidden size, lr, num layers\n",
    "    return 0.0\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "print(study.best_params)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
