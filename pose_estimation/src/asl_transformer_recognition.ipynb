{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee69f6e",
   "metadata": {},
   "source": [
    "# ASL Recognition with Transformer Architecture - Ultra-Optimized Pipeline\n",
    "\n",
    "## üöÄ Enhanced Transformer with Advanced Features\n",
    "\n",
    "This notebook implements a state-of-the-art ASL recognition system using:\n",
    "\n",
    "- **üéØ Transformer Architecture**: Multi-head attention for sequence modeling\n",
    "- **üîß Advanced GPU Optimizations**: Mixed precision, model compilation, speed tracking\n",
    "- **üìä Comprehensive Monitoring**: tqdm progress bars, real-time metrics\n",
    "- **üíæ Smart Checkpointing**: Auto-save best models with full state\n",
    "- **üîÑ Data Augmentation**: Spatial and temporal transformations\n",
    "- **üìà Rich Visualizations**: Training curves, confusion matrices, per-class analysis\n",
    "- **‚ö° Ultra-Fast Training**: All optimizations from TGCN pipeline + Transformer power\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "- **Input**: MediaPipe keypoint sequences (seq_len, 553, 3) - FIXED 'nodes' key\n",
    "- **Normalization**: Advanced SimpleNormalizer with proper handling\n",
    "- **Model**: Transformer encoder with positional encoding\n",
    "- **Features**: All advanced training features + GPU acceleration\n",
    "- **Target**: Match/exceed TGCN performance with Transformer efficiency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd6a83",
   "metadata": {},
   "source": [
    "## üìö Import All Required Libraries + GPU Optimizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0274a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Using device: cuda\n",
      "üöÄ PyTorch version: 2.7.0+cu118\n",
      "‚ö° CUDA available: True\n",
      "\n",
      "üöÄ Enabling Windows-Compatible GPU Optimizations:\n",
      "  ‚úÖ cuDNN benchmark enabled\n",
      "  ‚úÖ TF32 enabled for faster matmul\n",
      "  üìä GPU Memory: 4.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "# Fix the imports section - add missing autocast import\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.cuda.amp import GradScaler, autocast  # Added autocast import\n",
    "\n",
    "# Progress bars and timing\n",
    "from tqdm.auto import tqdm, trange\n",
    "import time\n",
    "\n",
    "# Data handling and visualization\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üéØ Using device: {device}\")\n",
    "print(f\"üöÄ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚ö° CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# üöÄ Enable Windows-compatible GPU optimizations\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nüöÄ Enabling Windows-Compatible GPU Optimizations:\")\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize cuDNN\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    print(\"  ‚úÖ cuDNN benchmark enabled\")\n",
    "    print(\"  ‚úÖ TF32 enabled for faster matmul\")\n",
    "    \n",
    "    # Check GPU memory\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"  üìä GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected - training will be slower on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e7c3f",
   "metadata": {},
   "source": [
    "## üìä Configuration and Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54a296b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Ultra-Optimized Transformer Configuration:\n",
      "  max_seq_len: 50\n",
      "  num_nodes: 553\n",
      "  num_features: 3\n",
      "  max_classes: 50\n",
      "  test_size: 0.2\n",
      "  val_size: 0.15\n",
      "  batch_size: 32\n",
      "  d_model: 128\n",
      "  nhead: 8\n",
      "  num_layers: 4\n",
      "  dropout: 0.1\n",
      "  dim_feedforward: 512\n",
      "  num_epochs: 100\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  patience: 15\n",
      "  min_lr: 1e-06\n",
      "  use_mixed_precision: True\n",
      "  pin_memory: True\n",
      "  non_blocking: True\n",
      "  compile_model: False\n",
      "  use_channels_last: False\n",
      "  gradient_accumulation: 1\n",
      "  use_augmentation: True\n",
      "  aug_probability: 0.2\n",
      "  spatial_aug_strength: 0.05\n",
      "  temporal_aug_strength: 0.1\n",
      "  num_workers: 0\n",
      "  prefetch_factor: 2\n",
      "  persistent_workers: False\n",
      "  save_checkpoints: True\n",
      "  checkpoint_dir: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints\n",
      "  scheduler_type: OneCycleLR\n",
      "  optimizer_type: AdamW\n",
      "  checkpoint_frequency: 10\n",
      "  input_dim: 1659\n",
      "\n",
      "üìÅ Data directory: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints\n",
      "üíæ Checkpoint directory: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints\n",
      "  ‚ö†Ô∏è  Limited GPU memory detected - using conservative settings\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "DATA_DIR = r'f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints'\n",
    "CHECKPOINT_DIR = r'f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints'\n",
    "MODEL_SAVE_PATH = os.path.join(CHECKPOINT_DIR, 'best_transformer_model.pth')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# üöÄ WINDOWS-COMPATIBLE GPU CONFIGURATION FOR SPEED üöÄ\n",
    "CONFIG = {\n",
    "    # Data parameters - OPTIMIZED FOR SPEED\n",
    "    'max_seq_len': 50,          # Sequence length for padding/truncation\n",
    "    'num_nodes': 553,           # 33 pose + 42 hands + 478 face landmarks\n",
    "    'num_features': 3,          # x, y, z coordinates\n",
    "    'max_classes': 50,          # üöÄ Limit classes for faster training\n",
    "    'test_size': 0.2,           # Train/test split ratio\n",
    "    'val_size': 0.15,           # Validation split ratio\n",
    "    'batch_size': 32,           # üöÄ Optimized batch size for GPU efficiency\n",
    "    \n",
    "    # Model architecture - TRANSFORMER SPECIFIC\n",
    "    'd_model': 128,             # Transformer model dimension\n",
    "    'nhead': 8,                 # Number of attention heads\n",
    "    'num_layers': 4,            # Number of transformer layers\n",
    "    'dropout': 0.1,             # Dropout rate\n",
    "    'dim_feedforward': 512,     # Feedforward dimension\n",
    "    \n",
    "    # Training parameters - OPTIMIZED FOR SPEED\n",
    "    'num_epochs': 100,          # Maximum training epochs\n",
    "    'learning_rate': 0.001,     # Initial learning rate\n",
    "    'weight_decay': 1e-4,       # L2 regularization\n",
    "    'patience': 15,             # Early stopping patience\n",
    "    'min_lr': 1e-6,             # Minimum learning rate\n",
    "    \n",
    "    # üöÄ WINDOWS-COMPATIBLE GPU OPTIMIZATION SETTINGS üöÄ\n",
    "    'use_mixed_precision': True,  # üöÄ Enable AMP for 2x speed\n",
    "    'pin_memory': True,           # üöÄ Faster CPU->GPU transfer\n",
    "    'non_blocking': True,         # üöÄ Async GPU transfers\n",
    "    'compile_model': False,       # üöÄ DISABLED - Triton not available on Windows\n",
    "    'use_channels_last': False,   # üöÄ DISABLED - Can cause issues on some Windows setups\n",
    "    'gradient_accumulation': 1,   # No gradient accumulation for speed\n",
    "    \n",
    "    # Data augmentation - SIMPLIFIED FOR SPEED\n",
    "    'use_augmentation': True,     # Enable data augmentation\n",
    "    'aug_probability': 0.2,       # üöÄ Probability of applying augmentation\n",
    "    'spatial_aug_strength': 0.05, # Spatial augmentation strength\n",
    "    'temporal_aug_strength': 0.1, # Temporal augmentation strength\n",
    "    \n",
    "    # DataLoader optimization üöÄ\n",
    "    'num_workers': 0,             # üöÄ Set to 0 for Windows/Jupyter compatibility\n",
    "    'prefetch_factor': 2,         # üöÄ Prefetch batches\n",
    "    'persistent_workers': False,  # üöÄ Don't keep workers alive (Windows compatibility)\n",
    "    \n",
    "    # üöÄ MISSING CONFIGURATION KEYS - ADDED üöÄ\n",
    "    'save_checkpoints': True,     # Enable model checkpointing\n",
    "    'checkpoint_dir': CHECKPOINT_DIR,  # Checkpoint directory\n",
    "    'scheduler_type': 'OneCycleLR',    # Learning rate scheduler type\n",
    "    'optimizer_type': 'AdamW',         # Optimizer type\n",
    "    'checkpoint_frequency': 10,        # Save checkpoint every N epochs\n",
    "}\n",
    "\n",
    "# Calculate input dimension\n",
    "CONFIG['input_dim'] = CONFIG['num_nodes'] * CONFIG['num_features']\n",
    "\n",
    "print(\"üìã Ultra-Optimized Transformer Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"üíæ Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# üöÄ Adjust config based on GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    if gpu_memory < 6:\n",
    "        print(\"  ‚ö†Ô∏è  Limited GPU memory detected - using conservative settings\")\n",
    "        CONFIG['batch_size'] = min(CONFIG['batch_size'], 24)\n",
    "        CONFIG['d_model'] = min(CONFIG['d_model'], 96)\n",
    "else:\n",
    "    CONFIG['batch_size'] = 16\n",
    "    CONFIG['use_mixed_precision'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ac145",
   "metadata": {},
   "source": [
    "## Advanced Data Normalization Class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8071a5",
   "metadata": {},
   "source": [
    "## üéØ Hyperparameter Tuning for 69% Target Accuracy\n",
    "\n",
    "Based on your successful 69% Transformer implementation, let's implement targeted hyperparameter configurations.\n",
    "We'll test multiple proven configurations for sequence classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "612f881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Implementing Hyperparameter Tuning for Target ~69% Accuracy\n",
      "======================================================================\n",
      "üìä Available Optimized Configurations:\n",
      "\n",
      "  üîß config_1_powerful:\n",
      "    üìê d_model: 256, layers: 6, heads: 8\n",
      "    üìö LR: 0.0005, batch_size: 16\n",
      "    üíæ Est. params: ~1573K\n",
      "\n",
      "  üîß config_2_balanced:\n",
      "    üìê d_model: 192, layers: 4, heads: 8\n",
      "    üìö LR: 0.0008, batch_size: 20\n",
      "    üíæ Est. params: ~590K\n",
      "\n",
      "  üîß config_3_efficient:\n",
      "    üìê d_model: 128, layers: 3, heads: 8\n",
      "    üìö LR: 0.0012, batch_size: 28\n",
      "    üíæ Est. params: ~197K\n",
      "\n",
      "  üîß config_4_deep:\n",
      "    üìê d_model: 160, layers: 8, heads: 10\n",
      "    üìö LR: 0.0003, batch_size: 12\n",
      "    üíæ Est. params: ~819K\n",
      "\n",
      "üéØ Selecting Optimal Configuration...\n",
      "üìä Available GPU Memory: 4.0 GB\n",
      "‚úÖ Selected: DEEP configuration (optimized for limited memory)\n",
      "\n",
      "üîÑ Applying config_4_deep configuration...\n",
      "  üîß d_model: 160\n",
      "  üîß nhead: 10\n",
      "  üîß num_layers: 8\n",
      "  üîß dropout: 0.25\n",
      "  üîß dim_feedforward: 640\n",
      "  üîß learning_rate: 0.0003\n",
      "  üîß batch_size: 12\n",
      "  üîß weight_decay: 0.001\n",
      "  üîß patience: 25\n",
      "  ‚ö° scheduler_type: CosineAnnealingWarmRestarts\n",
      "  ‚ö° warmup_epochs: 5\n",
      "  ‚ö° label_smoothing: 0.15\n",
      "  ‚ö° gradient_clip_norm: 0.5\n",
      "  ‚ö° use_layer_norm: True\n",
      "  ‚ö° positional_encoding_type: learnable\n",
      "\n",
      "üìä OPTIMIZED MODEL SPECIFICATIONS:\n",
      "  üß† Estimated Parameters: ~8.06M\n",
      "  üíæ Estimated Model Size: ~30.7MB\n",
      "  üéØ Target Accuracy: ~69% (matching your successful implementation)\n",
      "  ‚ö° Expected Training Time: ~7082s per epoch\n",
      "\n",
      "üöÄ Configuration optimization complete! Ready for high-performance training.\n"
     ]
    }
   ],
   "source": [
    "# üéØ HYPERPARAMETER TUNING - TARGETING 69% ACCURACY üéØ\n",
    "# Based on successful Transformer implementations for sequence classification\n",
    "\n",
    "print(\"üéØ Implementing Hyperparameter Tuning for Target ~69% Accuracy\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save original config\n",
    "ORIGINAL_CONFIG = CONFIG.copy()\n",
    "\n",
    "# üìä OPTIMIZED CONFIGURATIONS - Multiple proven setups\n",
    "OPTIMIZED_CONFIGS = {\n",
    "    'config_1_powerful': {\n",
    "        # More powerful model with proven architecture\n",
    "        'd_model': 256,              # üöÄ Increased from 96 -> 256\n",
    "        'nhead': 8,                  # Keep 8 heads (256/8 = 32 per head)\n",
    "        'num_layers': 6,             # üöÄ Increased layers for better representation\n",
    "        'dropout': 0.2,              # üöÄ Increased dropout for regularization  \n",
    "        'dim_feedforward': 1024,     # üöÄ Larger feedforward (4x d_model)\n",
    "        'learning_rate': 0.0005,     # üöÄ Lower LR for stability\n",
    "        'batch_size': 16,            # üöÄ Smaller batch for larger model\n",
    "        'weight_decay': 1e-3,        # üöÄ Stronger regularization\n",
    "        'patience': 20,              # More patience for convergence\n",
    "    },\n",
    "    \n",
    "    'config_2_balanced': {\n",
    "        # Balanced configuration - sweet spot\n",
    "        'd_model': 192,              # üöÄ Increased from 96 -> 192\n",
    "        'nhead': 8,                  # 192/8 = 24 per head\n",
    "        'num_layers': 4,             # Keep 4 layers\n",
    "        'dropout': 0.15,             # üöÄ Slight increase in dropout\n",
    "        'dim_feedforward': 768,      # 4x d_model\n",
    "        'learning_rate': 0.0008,     # üöÄ Slightly lower LR\n",
    "        'batch_size': 20,            # Medium batch size\n",
    "        'weight_decay': 5e-4,        # Balanced regularization\n",
    "        'patience': 18,\n",
    "    },\n",
    "    \n",
    "    'config_3_efficient': {\n",
    "        # Efficient but effective configuration\n",
    "        'd_model': 128,              # Back to original 128\n",
    "        'nhead': 8,                  # 128/8 = 16 per head\n",
    "        'num_layers': 3,             # üöÄ Fewer layers, focus on quality\n",
    "        'dropout': 0.3,              # üöÄ Higher dropout for generalization\n",
    "        'dim_feedforward': 512,      # 4x d_model\n",
    "        'learning_rate': 0.0012,     # üöÄ Slightly higher LR for faster convergence\n",
    "        'batch_size': 28,            # Larger batch for efficiency\n",
    "        'weight_decay': 2e-4,        # Light regularization\n",
    "        'patience': 15,\n",
    "    },\n",
    "    \n",
    "    'config_4_deep': {\n",
    "        # Deeper model with aggressive regularization\n",
    "        'd_model': 160,              # üöÄ Custom dimension\n",
    "        'nhead': 10,                 # üöÄ More heads (160/10 = 16 per head)\n",
    "        'num_layers': 8,             # üöÄ Deep model\n",
    "        'dropout': 0.25,             # Strong regularization\n",
    "        'dim_feedforward': 640,      # 4x d_model\n",
    "        'learning_rate': 0.0003,     # üöÄ Low LR for deep model stability\n",
    "        'batch_size': 12,            # Small batch for deep model\n",
    "        'weight_decay': 1e-3,        # Strong weight decay\n",
    "        'patience': 25,              # Extra patience for deep model\n",
    "    }\n",
    "}\n",
    "\n",
    "# üöÄ ADVANCED TRAINING OPTIMIZATIONS\n",
    "ADVANCED_OPTIMIZATIONS = {\n",
    "    'scheduler_type': 'CosineAnnealingWarmRestarts',  # üöÄ Better than OneCycleLR for transformers\n",
    "    'warmup_epochs': 5,                               # üöÄ Learning rate warmup\n",
    "    'label_smoothing': 0.15,                         # üöÄ Better than 0.1 for transformers\n",
    "    'gradient_clip_norm': 0.5,                       # üöÄ Tighter gradient clipping\n",
    "    'use_layer_norm': True,                          # üöÄ Additional layer normalization\n",
    "    'positional_encoding_type': 'learnable',         # üöÄ Learnable vs fixed positional encoding\n",
    "}\n",
    "\n",
    "print(\"üìä Available Optimized Configurations:\")\n",
    "for config_name, config in OPTIMIZED_CONFIGS.items():\n",
    "    estimated_params = config['d_model'] * config['d_model'] * config['num_layers'] * 4  # Rough estimate\n",
    "    print(f\"\\n  üîß {config_name}:\")\n",
    "    print(f\"    üìê d_model: {config['d_model']}, layers: {config['num_layers']}, heads: {config['nhead']}\")\n",
    "    print(f\"    üìö LR: {config['learning_rate']}, batch_size: {config['batch_size']}\")\n",
    "    print(f\"    üíæ Est. params: ~{estimated_params/1000:.0f}K\")\n",
    "\n",
    "# üéØ SELECT OPTIMAL CONFIGURATION\n",
    "print(\"\\nüéØ Selecting Optimal Configuration...\")\n",
    "\n",
    "# Check GPU memory and select best config\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"üìä Available GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    if gpu_memory >= 8:\n",
    "        selected_config = 'config_1_powerful'\n",
    "        print(\"‚úÖ Selected: POWERFUL configuration (8GB+ GPU)\")\n",
    "    elif gpu_memory >= 6:\n",
    "        selected_config = 'config_2_balanced' \n",
    "        print(\"‚úÖ Selected: BALANCED configuration (6GB+ GPU)\")\n",
    "    elif gpu_memory >= 4:\n",
    "        selected_config = 'config_3_efficient'\n",
    "        print(\"‚úÖ Selected: EFFICIENT configuration (4GB+ GPU)\")\n",
    "    else:\n",
    "        selected_config = 'config_4_deep'\n",
    "        print(\"‚úÖ Selected: DEEP configuration (optimized for limited memory)\")\n",
    "else:\n",
    "    selected_config = 'config_3_efficient'\n",
    "    print(\"‚úÖ Selected: EFFICIENT configuration (CPU fallback)\")\n",
    "\n",
    "# üöÄ APPLY SELECTED CONFIGURATION\n",
    "optimal_config = OPTIMIZED_CONFIGS[selected_config]\n",
    "print(f\"\\nüîÑ Applying {selected_config} configuration...\")\n",
    "\n",
    "# Update CONFIG with optimal settings\n",
    "for key, value in optimal_config.items():\n",
    "    CONFIG[key] = value\n",
    "    print(f\"  üîß {key}: {CONFIG[key]}\")\n",
    "\n",
    "# Apply advanced optimizations\n",
    "for key, value in ADVANCED_OPTIMIZATIONS.items():\n",
    "    CONFIG[key] = value\n",
    "    print(f\"  ‚ö° {key}: {CONFIG[key]}\")\n",
    "\n",
    "# üéØ CALCULATE MODEL COMPLEXITY\n",
    "input_dim = CONFIG['num_nodes'] * CONFIG['num_features']\n",
    "estimated_total_params = (\n",
    "    input_dim * CONFIG['d_model'] +  # Input projection\n",
    "    CONFIG['d_model'] * CONFIG['d_model'] * CONFIG['nhead'] * CONFIG['num_layers'] * 3 +  # Attention\n",
    "    CONFIG['d_model'] * CONFIG['dim_feedforward'] * CONFIG['num_layers'] * 2 +  # FFN\n",
    "    CONFIG['d_model'] * CONFIG['max_classes']  # Classification head\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä OPTIMIZED MODEL SPECIFICATIONS:\")\n",
    "print(f\"  üß† Estimated Parameters: ~{estimated_total_params/1000000:.2f}M\")\n",
    "print(f\"  üíæ Estimated Model Size: ~{estimated_total_params * 4 / 1024 / 1024:.1f}MB\")\n",
    "print(f\"  üéØ Target Accuracy: ~69% (matching your successful implementation)\")\n",
    "print(f\"  ‚ö° Expected Training Time: ~{CONFIG['num_epochs'] * len(range(425)) // CONFIG['batch_size'] * 2:.0f}s per epoch\")\n",
    "\n",
    "print(\"\\nüöÄ Configuration optimization complete! Ready for high-performance training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb186ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNormalizer:\n",
    "    \"\"\"Advanced normalizer with proper keypoint handling and validation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.center_x = None\n",
    "        self.center_y = None\n",
    "        self.scale = None\n",
    "        self.fitted = False\n",
    "        # Add mean and std for compatibility with deployment code\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        \n",
    "    def fit(self, sequences):\n",
    "        \"\"\"Fit normalizer on training data sequences\"\"\"\n",
    "        print(\"üîß Fitting normalizer on training data...\")\n",
    "        \n",
    "        all_points = []\n",
    "        valid_count = 0\n",
    "        total_count = 0\n",
    "        \n",
    "        for seq in tqdm(sequences, desc=\"Processing sequences for normalization\"):\n",
    "            if seq.size > 0:\n",
    "                # Flatten sequence to get all points\n",
    "                flat_seq = seq.reshape(-1, seq.shape[-1])\n",
    "                \n",
    "                # Only use x, y coordinates for normalization (ignore z if present)\n",
    "                if flat_seq.shape[1] >= 2:\n",
    "                    xy_points = flat_seq[:, :2]\n",
    "                    \n",
    "                    # Filter out zero/invalid points\n",
    "                    valid_mask = ~(np.isnan(xy_points).any(axis=1) | \n",
    "                                  np.isinf(xy_points).any(axis=1) |\n",
    "                                  (np.abs(xy_points) < 1e-6).all(axis=1))\n",
    "                    \n",
    "                    valid_points = xy_points[valid_mask]\n",
    "                    if len(valid_points) > 0:\n",
    "                        all_points.append(valid_points)\n",
    "                        valid_count += len(valid_points)\n",
    "                    \n",
    "                    total_count += len(xy_points)\n",
    "        \n",
    "        print(f\"  üìä Valid keypoints: {valid_count:,} / {total_count:,} ({100*valid_count/max(total_count,1):.1f}%)\")\n",
    "        \n",
    "        if all_points:\n",
    "            all_points = np.vstack(all_points)\n",
    "            \n",
    "            # Use robust statistics for better normalization\n",
    "            self.center_x = np.median(all_points[:, 0])\n",
    "            self.center_y = np.median(all_points[:, 1])\n",
    "            \n",
    "            # Calculate scale using interquartile range for robustness\n",
    "            distances = np.sqrt((all_points[:, 0] - self.center_x)**2 + \n",
    "                              (all_points[:, 1] - self.center_y)**2)\n",
    "            self.scale = np.percentile(distances, 95)\n",
    "            \n",
    "            if self.scale == 0 or np.isnan(self.scale):\n",
    "                self.scale = 1.0\n",
    "                \n",
    "            # Calculate mean and std for deployment compatibility\n",
    "            self.mean = np.array([self.center_x, self.center_y, 0.0])  # x, y, z\n",
    "            self.std = np.array([self.scale, self.scale, 1.0])  # x, y, z\n",
    "                \n",
    "            self.fitted = True\n",
    "            \n",
    "            print(f\"  üìà Normalization parameters:\")\n",
    "            print(f\"    Center: ({self.center_x:.3f}, {self.center_y:.3f})\")\n",
    "            print(f\"    Scale: {self.scale:.3f}\")\n",
    "        else:\n",
    "            print(\"  ‚ö†Ô∏è  No valid points found, using default normalization\")\n",
    "            self.center_x, self.center_y, self.scale = 0.0, 0.0, 1.0\n",
    "            self.mean = np.array([0.0, 0.0, 0.0])\n",
    "            self.std = np.array([1.0, 1.0, 1.0])\n",
    "            self.fitted = True\n",
    "    \n",
    "    def transform(self, sequence):\n",
    "        \"\"\"Transform a sequence using fitted parameters\"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Normalizer must be fitted before transform\")\n",
    "            \n",
    "        if sequence.size == 0:\n",
    "            return sequence\n",
    "            \n",
    "        normalized = sequence.copy().astype(np.float32)\n",
    "        \n",
    "        # Normalize x, y coordinates\n",
    "        if normalized.shape[-1] >= 2:\n",
    "            normalized[..., 0] = (normalized[..., 0] - self.center_x) / self.scale\n",
    "            normalized[..., 1] = (normalized[..., 1] - self.center_y) / self.scale\n",
    "        \n",
    "        # Handle NaN and infinite values\n",
    "        normalized = np.nan_to_num(normalized, nan=0.0, posinf=2.0, neginf=-2.0)\n",
    "        \n",
    "        # Clip to reasonable range\n",
    "        normalized = np.clip(normalized, -3, 3)\n",
    "        \n",
    "        return normalized\n",
    "    \n",
    "    def fit_transform(self, sequences):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        self.fit(sequences)\n",
    "        return [self.transform(seq) for seq in sequences]\n",
    "\n",
    "# Data augmentation functions\n",
    "def apply_spatial_augmentation(sequence, scale_range=0.1, translation_range=0.05, \n",
    "                             rotation_range=0.1, noise_std=0.01):\n",
    "    \"\"\"Apply spatial augmentations to a sequence\"\"\"\n",
    "    aug_seq = sequence.copy()\n",
    "    \n",
    "    if aug_seq.size == 0:\n",
    "        return aug_seq\n",
    "    \n",
    "    # Random scaling\n",
    "    if scale_range > 0:\n",
    "        scale_factor = 1 + np.random.uniform(-scale_range, scale_range)\n",
    "        aug_seq[..., :2] *= scale_factor\n",
    "    \n",
    "    # Random translation\n",
    "    if translation_range > 0:\n",
    "        tx = np.random.uniform(-translation_range, translation_range)\n",
    "        ty = np.random.uniform(-translation_range, translation_range)\n",
    "        aug_seq[..., 0] += tx\n",
    "        aug_seq[..., 1] += ty\n",
    "    \n",
    "    # Random rotation (simple 2D rotation)\n",
    "    if rotation_range > 0:\n",
    "        angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "        cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "        \n",
    "        x_coords = aug_seq[..., 0].copy()\n",
    "        y_coords = aug_seq[..., 1].copy()\n",
    "        \n",
    "        aug_seq[..., 0] = x_coords * cos_a - y_coords * sin_a\n",
    "        aug_seq[..., 1] = x_coords * sin_a + y_coords * cos_a\n",
    "    \n",
    "    # Add noise\n",
    "    if noise_std > 0:\n",
    "        noise = np.random.normal(0, noise_std, aug_seq.shape)\n",
    "        aug_seq += noise\n",
    "    \n",
    "    return aug_seq\n",
    "\n",
    "def apply_temporal_augmentation(sequence, speed_range=0.2):\n",
    "    \"\"\"Apply temporal augmentations (speed changes)\"\"\"\n",
    "    if sequence.size == 0 or len(sequence) < 2:\n",
    "        return sequence\n",
    "    \n",
    "    # Random speed change\n",
    "    speed_factor = 1 + np.random.uniform(-speed_range, speed_range)\n",
    "    new_length = max(1, int(len(sequence) * speed_factor))\n",
    "    \n",
    "    # Interpolate to new length\n",
    "    indices = np.linspace(0, len(sequence) - 1, new_length)\n",
    "    \n",
    "    aug_seq = np.zeros((new_length, sequence.shape[1], sequence.shape[2]))\n",
    "    \n",
    "    for i in range(sequence.shape[1]):  # For each keypoint\n",
    "        for j in range(sequence.shape[2]):  # For each coordinate\n",
    "            aug_seq[:, i, j] = np.interp(indices, np.arange(len(sequence)), sequence[:, i, j])\n",
    "    \n",
    "    return aug_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a2500",
   "metadata": {},
   "source": [
    "## Dataset Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aa610a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced ASLKeypointDataset with 'nodes' key support and validation ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ASLKeypointDataset(Dataset):\n",
    "    \"\"\"Enhanced ASL Dataset with proper 'nodes' key handling and validation\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, max_seq_len=50, split='train', test_size=0.2, \n",
    "                 random_state=42, use_subset=False, max_classes=None, normalizer=None,\n",
    "                 use_augmentation=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.split = split\n",
    "        self.normalizer = normalizer\n",
    "        self.use_augmentation = use_augmentation\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.word_to_idx = {}\n",
    "        self.idx_to_word = {}\n",
    "        self.class_names = []\n",
    "        \n",
    "        print(f\"üîÑ Loading {split} dataset from {data_dir}...\")\n",
    "        self._load_and_split_data(test_size, random_state, use_subset, max_classes)\n",
    "        \n",
    "    def _load_and_split_data(self, test_size, random_state, use_subset, max_classes):\n",
    "        \"\"\"Load data and create train/test splits\"\"\"\n",
    "        \n",
    "        # Find all word directories\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            raise FileNotFoundError(f\"Data directory not found: {self.data_dir}\")\n",
    "            \n",
    "        word_dirs = [d for d in os.listdir(self.data_dir) \n",
    "                    if os.path.isdir(os.path.join(self.data_dir, d))]\n",
    "        word_dirs = sorted(word_dirs)\n",
    "        \n",
    "        if use_subset and max_classes:\n",
    "            word_dirs = word_dirs[:max_classes]\n",
    "            print(f\"  üìä Using subset: {len(word_dirs)} classes\")\n",
    "        \n",
    "        # Collect all data first\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        current_idx = 0\n",
    "        \n",
    "        for word in tqdm(word_dirs, desc=\"Loading classes\"):\n",
    "            word_dir = os.path.join(self.data_dir, word)\n",
    "            npz_files = glob.glob(os.path.join(word_dir, \"*.npz\"))\n",
    "            \n",
    "            if len(npz_files) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Add word to mapping\n",
    "            self.word_to_idx[word] = current_idx\n",
    "            self.idx_to_word[current_idx] = word\n",
    "            self.class_names.append(word)\n",
    "            \n",
    "            valid_samples = 0\n",
    "            for npz_file in npz_files:\n",
    "                try:\n",
    "                    data = np.load(npz_file)\n",
    "                    \n",
    "                    # Look for 'nodes' key (new format) or 'pose' key (old format)\n",
    "                    if 'nodes' in data:\n",
    "                        keypoints = data['nodes']\n",
    "                    elif 'pose' in data:\n",
    "                        keypoints = data['pose']\n",
    "                        print(f\"  ‚ö†Ô∏è  Using 'pose' key for {npz_file} (should be 'nodes')\")\n",
    "                    else:\n",
    "                        print(f\"  ‚ùå No valid keypoint data in {npz_file}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Validate shape\n",
    "                    if keypoints.ndim == 3 and keypoints.shape[0] > 0:\n",
    "                        # Apply normalization if provided\n",
    "                        if self.normalizer:\n",
    "                            keypoints = self.normalizer.transform(keypoints)\n",
    "                        \n",
    "                        # Pad or truncate to target length\n",
    "                        processed = self._pad_or_truncate(keypoints)\n",
    "                        \n",
    "                        all_data.append(processed)\n",
    "                        all_labels.append(current_idx)\n",
    "                        valid_samples += 1\n",
    "                    else:\n",
    "                        print(f\"  ‚ö†Ô∏è  Invalid keypoint shape {keypoints.shape} in {npz_file}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ùå Error loading {npz_file}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  üìÅ {word}: {valid_samples} valid samples\")\n",
    "            current_idx += 1\n",
    "        \n",
    "        # Convert to arrays\n",
    "        all_data = np.array(all_data)\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        print(f\"  üìä Total samples: {len(all_data)}\")\n",
    "        print(f\"  üìä Total classes: {len(self.class_names)}\")\n",
    "        \n",
    "        # Create train/test split\n",
    "        if len(all_data) > 0:\n",
    "            train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "                all_data, all_labels, test_size=test_size, random_state=random_state,\n",
    "                stratify=all_labels if len(np.unique(all_labels)) > 1 else None\n",
    "            )\n",
    "            \n",
    "            if self.split == 'train':\n",
    "                self.data = train_data\n",
    "                self.labels = train_labels\n",
    "                print(f\"  ‚úÖ Train split: {len(self.data)} samples\")\n",
    "            else:\n",
    "                self.data = test_data  \n",
    "                self.labels = test_labels\n",
    "                print(f\"  ‚úÖ Test split: {len(self.data)} samples\")\n",
    "        else:\n",
    "            raise ValueError(\"No valid samples found in dataset\")\n",
    "            \n",
    "        self.num_classes = len(self.class_names)\n",
    "        \n",
    "    def _pad_or_truncate(self, sequence):\n",
    "        \"\"\"Pad or truncate sequence to target length\"\"\"\n",
    "        if len(sequence) >= self.max_seq_len:\n",
    "            # Truncate\n",
    "            return sequence[:self.max_seq_len]\n",
    "        else:\n",
    "            # Pad with zeros\n",
    "            padding = np.zeros((self.max_seq_len - len(sequence), \n",
    "                              sequence.shape[1], sequence.shape[2]))\n",
    "            return np.vstack([sequence, padding])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data[idx].copy()\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply data augmentation if enabled\n",
    "        if self.use_augmentation and self.split == 'train':\n",
    "            if np.random.random() < CONFIG['aug_probability']:\n",
    "                # Apply spatial augmentation\n",
    "                if np.random.random() < 0.5:\n",
    "                    sequence = apply_spatial_augmentation(\n",
    "                        sequence,\n",
    "                        scale_range=CONFIG['spatial_aug_strength'],\n",
    "                        translation_range=CONFIG['spatial_aug_strength']\n",
    "                    )\n",
    "                \n",
    "                # Apply temporal augmentation\n",
    "                if np.random.random() < 0.3:\n",
    "                    aug_seq = apply_temporal_augmentation(\n",
    "                        sequence, speed_range=CONFIG['temporal_aug_strength']\n",
    "                    )\n",
    "                    # Ensure consistent length\n",
    "                    if aug_seq.shape[0] != self.max_seq_len:\n",
    "                        sequence = self._pad_or_truncate(aug_seq)\n",
    "                    else:\n",
    "                        sequence = aug_seq\n",
    "        \n",
    "        return torch.FloatTensor(sequence), torch.LongTensor([label])[0]\n",
    "\n",
    "print(\"‚úÖ Enhanced ASLKeypointDataset with 'nodes' key support and validation ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27fb42f",
   "metadata": {},
   "source": [
    "## Transformer Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "291619c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class TransformerASL(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, num_classes, seq_len, dropout=0.1):\n",
    "        super(TransformerASL, self).__init__()\n",
    "        \n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, seq_len)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_dim)\n",
    "        x = self.input_projection(x) * np.sqrt(self.d_model)\n",
    "        x = x.transpose(0, 1)  # (seq_len, batch_size, d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.transpose(0, 1)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        # Create padding mask\n",
    "        src_key_padding_mask = torch.all(x == 0, dim=-1)\n",
    "        \n",
    "        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Global average pooling\n",
    "        mask = (~src_key_padding_mask).float().unsqueeze(-1)\n",
    "        x = (x * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)\n",
    "        \n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d94b4e",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Metrics Tracking and Training Utilities\n",
    "\n",
    "Advanced metrics tracking with visualizations and training utilities from TGCN pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92542a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced metrics tracking and training utilities ready!\n"
     ]
    }
   ],
   "source": [
    "class MetricsTracker:\n",
    "    \"\"\"Track training metrics and progress with advanced visualizations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "        self.learning_rates = []\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_epoch = 0\n",
    "        self.epoch_times = []\n",
    "        self.samples_per_second = []\n",
    "    \n",
    "    def update(self, train_loss, train_acc, val_loss, val_acc, lr, epoch_time=None, samples_per_sec=None):\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.train_accuracies.append(train_acc)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_accuracies.append(val_acc)\n",
    "        self.learning_rates.append(lr)\n",
    "        \n",
    "        if epoch_time is not None:\n",
    "            self.epoch_times.append(epoch_time)\n",
    "        if samples_per_sec is not None:\n",
    "            self.samples_per_second.append(samples_per_sec)\n",
    "        \n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            self.best_epoch = len(self.val_accuracies) - 1\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        \"\"\"Plot comprehensive training metrics\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        \n",
    "        # Loss plot\n",
    "        axes[0, 0].plot(self.train_losses, label='Train Loss', color='blue', linewidth=2)\n",
    "        axes[0, 0].plot(self.val_losses, label='Val Loss', color='red', linewidth=2)\n",
    "        axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        axes[0, 1].plot(self.train_accuracies, label='Train Acc', color='blue', linewidth=2)\n",
    "        axes[0, 1].plot(self.val_accuracies, label='Val Acc', color='red', linewidth=2)\n",
    "        axes[0, 1].axhline(y=self.best_val_acc, color='green', linestyle='--', \n",
    "                          label=f'Best Val Acc: {self.best_val_acc:.3f}%', linewidth=2)\n",
    "        axes[0, 1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Learning rate plot\n",
    "        axes[0, 2].plot(self.learning_rates, color='orange', linewidth=2)\n",
    "        axes[0, 2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "        axes[0, 2].set_xlabel('Epoch')\n",
    "        axes[0, 2].set_ylabel('Learning Rate')\n",
    "        axes[0, 2].set_yscale('log')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Validation accuracy zoomed\n",
    "        axes[1, 0].plot(self.val_accuracies, color='red', linewidth=2, marker='o', markersize=4)\n",
    "        axes[1, 0].axhline(y=self.best_val_acc, color='green', linestyle='--', linewidth=2)\n",
    "        axes[1, 0].set_title(f'Validation Accuracy\\n(Best: {self.best_val_acc:.3f}% at epoch {self.best_epoch+1})', \n",
    "                            fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Accuracy (%)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Training speed\n",
    "        if self.epoch_times:\n",
    "            axes[1, 1].plot(self.epoch_times, color='purple', linewidth=2)\n",
    "            axes[1, 1].set_title('Training Speed (Time per Epoch)', fontsize=14, fontweight='bold')\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].set_ylabel('Time (seconds)')\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'No timing data', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "            axes[1, 1].set_title('Training Speed (Time per Epoch)', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Samples per second\n",
    "        if self.samples_per_second:\n",
    "            axes[1, 2].plot(self.samples_per_second, color='green', linewidth=2)\n",
    "            axes[1, 2].set_title('Training Throughput', fontsize=14, fontweight='bold')\n",
    "            axes[1, 2].set_xlabel('Epoch')\n",
    "            axes[1, 2].set_ylabel('Samples/Second')\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 2].text(0.5, 0.5, 'No throughput data', ha='center', va='center', transform=axes[1, 2].transAxes)\n",
    "            axes[1, 2].set_title('Training Throughput', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    \"\"\"Calculate accuracy from model outputs and targets\"\"\"\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    total = targets.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "def train_epoch_with_progress(model, train_loader, criterion, optimizer, device, \n",
    "                             use_mixed_precision=False, scaler=None):\n",
    "    \"\"\"Train for one epoch with tqdm progress bar and optimizations\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    total_samples = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create progress bar for batches\n",
    "    train_pbar = tqdm(train_loader, desc='üöÄ Training', leave=False, \n",
    "                     bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_pbar):\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        # Move to device with non-blocking transfer if supported\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "        else:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Reshape data for transformer (batch_size, seq_len, features)\n",
    "        batch_size, seq_len, num_nodes, num_features = data.shape\n",
    "        data = data.view(batch_size, seq_len, num_nodes * num_features)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision training\n",
    "        if use_mixed_precision and scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        accuracy = calculate_accuracy(outputs, targets)\n",
    "        total_accuracy += accuracy\n",
    "        num_batches += 1\n",
    "        total_samples += batch_size\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{accuracy:.2f}%',\n",
    "            'AvgLoss': f'{total_loss/num_batches:.4f}'\n",
    "        })\n",
    "    \n",
    "    # Calculate training speed\n",
    "    total_time = time.time() - start_time\n",
    "    samples_per_second = total_samples / total_time if total_time > 0 else 0\n",
    "    \n",
    "    return total_loss / num_batches, total_accuracy / num_batches, samples_per_second\n",
    "\n",
    "def validate_epoch_with_progress(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch with tqdm progress bar\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Create progress bar for validation\n",
    "    val_pbar = tqdm(val_loader, desc='üîç Validation', leave=False,\n",
    "                   bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}, {rate_fmt}]')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_pbar:\n",
    "            # Move to device\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "            else:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # Reshape data for transformer\n",
    "            batch_size, seq_len, num_nodes, num_features = data.shape\n",
    "            data = data.view(batch_size, seq_len, num_nodes * num_features)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            accuracy = calculate_accuracy(outputs, targets)\n",
    "            total_accuracy += accuracy\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{accuracy:.2f}%',\n",
    "                'AvgAcc': f'{total_accuracy/num_batches:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return total_loss / num_batches, total_accuracy / num_batches\n",
    "\n",
    "print(\"‚úÖ Advanced metrics tracking and training utilities ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fcc6a",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ce01ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating enhanced datasets with proper train/val/test splits...\n",
      "üîÑ Loading train dataset from f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints...\n",
      "  üìä Using subset: 50 classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed9cecee71943fd814b3ac41dd675ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading classes:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÅ about: 8 valid samples\n",
      "  üìÅ accident: 13 valid samples\n",
      "  üìÅ africa: 13 valid samples\n",
      "  üìÅ again: 10 valid samples\n",
      "  üìÅ all: 13 valid samples\n",
      "  üìÅ always: 9 valid samples\n",
      "  üìÅ always: 9 valid samples\n",
      "  üìÅ animal: 10 valid samples\n",
      "  üìÅ apple: 13 valid samples\n",
      "  üìÅ approve: 11 valid samples\n",
      "  üìÅ argue: 10 valid samples\n",
      "  üìÅ arrive: 10 valid samples\n",
      "  üìÅ baby: 10 valid samples\n",
      "  üìÅ back: 7 valid samples\n",
      "  üìÅ animal: 10 valid samples\n",
      "  üìÅ apple: 13 valid samples\n",
      "  üìÅ approve: 11 valid samples\n",
      "  üìÅ argue: 10 valid samples\n",
      "  üìÅ arrive: 10 valid samples\n",
      "  üìÅ baby: 10 valid samples\n",
      "  üìÅ back: 7 valid samples\n",
      "  üìÅ backpack: 11 valid samples\n",
      "  üìÅ bad: 11 valid samples\n",
      "  üìÅ backpack: 11 valid samples\n",
      "  üìÅ bad: 11 valid samples\n",
      "  üìÅ bake: 8 valid samples\n",
      "  üìÅ balance: 11 valid samples\n",
      "  üìÅ ball: 11 valid samples\n",
      "  üìÅ banana: 10 valid samples\n",
      "  üìÅ bar: 10 valid samples\n",
      "  üìÅ basketball: 12 valid samples\n",
      "  üìÅ bake: 8 valid samples\n",
      "  üìÅ balance: 11 valid samples\n",
      "  üìÅ ball: 11 valid samples\n",
      "  üìÅ banana: 10 valid samples\n",
      "  üìÅ bar: 10 valid samples\n",
      "  üìÅ basketball: 12 valid samples\n",
      "  üìÅ bath: 10 valid samples\n",
      "  üìÅ bathroom: 10 valid samples\n",
      "  üìÅ bath: 10 valid samples\n",
      "  üìÅ bathroom: 10 valid samples\n",
      "  üìÅ beard: 10 valid samples\n",
      "  üìÅ because: 7 valid samples\n",
      "  üìÅ bed: 13 valid samples\n",
      "  üìÅ before: 17 valid samples\n",
      "  üìÅ behind: 9 valid samples\n",
      "  üìÅ bird: 12 valid samples\n",
      "  üìÅ beard: 10 valid samples\n",
      "  üìÅ because: 7 valid samples\n",
      "  üìÅ bed: 13 valid samples\n",
      "  üìÅ before: 17 valid samples\n",
      "  üìÅ behind: 9 valid samples\n",
      "  üìÅ bird: 12 valid samples\n",
      "  üìÅ birthday: 9 valid samples\n",
      "  üìÅ black: 13 valid samples\n",
      "  üìÅ birthday: 9 valid samples\n",
      "  üìÅ black: 13 valid samples\n",
      "  üìÅ blanket: 8 valid samples\n",
      "  üìÅ blue: 12 valid samples\n",
      "  üìÅ book: 10 valid samples\n",
      "  üìÅ bowling: 13 valid samples\n",
      "  üìÅ boy: 10 valid samples\n",
      "  üìÅ bring: 10 valid samples\n",
      "  üìÅ blanket: 8 valid samples\n",
      "  üìÅ blue: 12 valid samples\n",
      "  üìÅ book: 10 valid samples\n",
      "  üìÅ bowling: 13 valid samples\n",
      "  üìÅ boy: 10 valid samples\n",
      "  üìÅ bring: 10 valid samples\n",
      "  üìÅ brother: 11 valid samples\n",
      "  üìÅ brown: 11 valid samples\n",
      "  üìÅ business: 11 valid samples\n",
      "  üìÅ brother: 11 valid samples\n",
      "  üìÅ brown: 11 valid samples\n",
      "  üìÅ business: 11 valid samples\n",
      "  üìÅ but: 10 valid samples\n",
      "  üìÅ buy: 11 valid samples\n",
      "  üìÅ call: 11 valid samples\n",
      "  üìÅ can: 12 valid samples\n",
      "  üìÅ candy: 14 valid samples\n",
      "  üìÅ careful: 8 valid samples\n",
      "  üìÅ but: 10 valid samples\n",
      "  üìÅ buy: 11 valid samples\n",
      "  üìÅ call: 11 valid samples\n",
      "  üìÅ can: 12 valid samples\n",
      "  üìÅ candy: 14 valid samples\n",
      "  üìÅ careful: 8 valid samples\n",
      "  üìÅ cat: 11 valid samples\n",
      "  üìÅ catch: 9 valid samples\n",
      "  üìÅ center: 10 valid samples\n",
      "  üìÅ cat: 11 valid samples\n",
      "  üìÅ catch: 9 valid samples\n",
      "  üìÅ center: 10 valid samples\n",
      "  üìÅ cereal: 9 valid samples\n",
      "  üìä Total samples: 532\n",
      "  üìä Total classes: 50\n",
      "  üìÅ cereal: 9 valid samples\n",
      "  üìä Total samples: 532\n",
      "  üìä Total classes: 50\n",
      "  ‚úÖ Train split: 425 samples\n",
      "üîß Fitting normalizer on training data...\n",
      "üîß Fitting normalizer on training data...\n",
      "  ‚úÖ Train split: 425 samples\n",
      "üîß Fitting normalizer on training data...\n",
      "üîß Fitting normalizer on training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834a987827624c42a6c0d259885e8a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing sequences for normalization:   0%|          | 0/425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìä Valid keypoints: 10,784,367 / 11,751,250 (91.8%)\n",
      "  üìà Normalization parameters:\n",
      "    Center: (0.506, 0.237)\n",
      "    Scale: 0.445\n",
      "üîÑ Loading train dataset from f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints...\n",
      "  üìä Using subset: 50 classes\n",
      "  üìà Normalization parameters:\n",
      "    Center: (0.506, 0.237)\n",
      "    Scale: 0.445\n",
      "üîÑ Loading train dataset from f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints...\n",
      "  üìä Using subset: 50 classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314db39c69d3422fab216ad5284126bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading classes:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÅ about: 8 valid samples\n",
      "  üìÅ accident: 13 valid samples\n",
      "  üìÅ africa: 13 valid samples\n",
      "  üìÅ again: 10 valid samples\n",
      "  üìÅ all: 13 valid samples\n",
      "  üìÅ all: 13 valid samples\n",
      "  üìÅ always: 9 valid samples\n",
      "  üìÅ animal: 10 valid samples\n",
      "  üìÅ apple: 13 valid samples\n",
      "  üìÅ approve: 11 valid samples\n",
      "  üìÅ argue: 10 valid samples\n",
      "  üìÅ always: 9 valid samples\n",
      "  üìÅ animal: 10 valid samples\n",
      "  üìÅ apple: 13 valid samples\n",
      "  üìÅ approve: 11 valid samples\n",
      "  üìÅ argue: 10 valid samples\n",
      "  üìÅ arrive: 10 valid samples\n",
      "  üìÅ arrive: 10 valid samples\n",
      "  üìÅ baby: 10 valid samples\n",
      "  üìÅ back: 7 valid samples\n",
      "  üìÅ backpack: 11 valid samples\n",
      "  üìÅ bad: 11 valid samples\n",
      "  üìÅ bake: 8 valid samples\n",
      "  üìÅ balance: 11 valid samples\n",
      "  üìÅ baby: 10 valid samples\n",
      "  üìÅ back: 7 valid samples\n",
      "  üìÅ backpack: 11 valid samples\n",
      "  üìÅ bad: 11 valid samples\n",
      "  üìÅ bake: 8 valid samples\n",
      "  üìÅ balance: 11 valid samples\n",
      "  üìÅ ball: 11 valid samples\n",
      "  üìÅ banana: 10 valid samples\n",
      "  üìÅ bar: 10 valid samples\n",
      "  üìÅ basketball: 12 valid samples\n",
      "  üìÅ bath: 10 valid samples\n",
      "  üìÅ ball: 11 valid samples\n",
      "  üìÅ banana: 10 valid samples\n",
      "  üìÅ bar: 10 valid samples\n",
      "  üìÅ basketball: 12 valid samples\n",
      "  üìÅ bath: 10 valid samples\n",
      "  üìÅ bathroom: 10 valid samples\n",
      "  üìÅ beard: 10 valid samples\n",
      "  üìÅ because: 7 valid samples\n",
      "  üìÅ bed: 13 valid samples\n",
      "  üìÅ before: 17 valid samples\n",
      "  üìÅ behind: 9 valid samples\n",
      "  üìÅ bathroom: 10 valid samples\n",
      "  üìÅ beard: 10 valid samples\n",
      "  üìÅ because: 7 valid samples\n",
      "  üìÅ bed: 13 valid samples\n",
      "  üìÅ before: 17 valid samples\n",
      "  üìÅ behind: 9 valid samples\n",
      "  üìÅ bird: 12 valid samples\n",
      "  üìÅ birthday: 9 valid samples\n",
      "  üìÅ black: 13 valid samples\n",
      "  üìÅ blanket: 8 valid samples\n",
      "  üìÅ blue: 12 valid samples\n",
      "  üìÅ book: 10 valid samples\n",
      "  üìÅ bird: 12 valid samples\n",
      "  üìÅ birthday: 9 valid samples\n",
      "  üìÅ black: 13 valid samples\n",
      "  üìÅ blanket: 8 valid samples\n",
      "  üìÅ blue: 12 valid samples\n",
      "  üìÅ book: 10 valid samples\n",
      "  üìÅ bowling: 13 valid samples\n",
      "  üìÅ boy: 10 valid samples\n",
      "  üìÅ bring: 10 valid samples\n",
      "  üìÅ brother: 11 valid samples\n",
      "  üìÅ brown: 11 valid samples\n",
      "  üìÅ business: 11 valid samples\n",
      "  üìÅ but: 10 valid samples\n",
      "  üìÅ bowling: 13 valid samples\n",
      "  üìÅ boy: 10 valid samples\n",
      "  üìÅ bring: 10 valid samples\n",
      "  üìÅ brother: 11 valid samples\n",
      "  üìÅ brown: 11 valid samples\n",
      "  üìÅ business: 11 valid samples\n",
      "  üìÅ but: 10 valid samples\n",
      "  üìÅ buy: 11 valid samples\n",
      "  üìÅ call: 11 valid samples\n",
      "  üìÅ can: 12 valid samples\n",
      "  üìÅ candy: 14 valid samples\n",
      "  üìÅ careful: 8 valid samples\n",
      "  üìÅ cat: 11 valid samples\n",
      "  üìÅ catch: 9 valid samples\n",
      "  üìÅ buy: 11 valid samples\n",
      "  üìÅ call: 11 valid samples\n",
      "  üìÅ can: 12 valid samples\n",
      "  üìÅ candy: 14 valid samples\n",
      "  üìÅ careful: 8 valid samples\n",
      "  üìÅ cat: 11 valid samples\n",
      "  üìÅ catch: 9 valid samples\n",
      "  üìÅ center: 10 valid samples\n",
      "  üìÅ cereal: 9 valid samples\n",
      "  üìä Total samples: 532\n",
      "  üìä Total classes: 50\n",
      "  üìÅ center: 10 valid samples\n",
      "  üìÅ cereal: 9 valid samples\n",
      "  üìä Total samples: 532\n",
      "  üìä Total classes: 50\n",
      "  ‚úÖ Train split: 425 samples\n",
      "üîÑ Loading test dataset from f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints...\n",
      "  üìä Using subset: 50 classes\n",
      "  ‚úÖ Train split: 425 samples\n",
      "üîÑ Loading test dataset from f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints...\n",
      "  üìä Using subset: 50 classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce24302394ab4c9888d034b0bb6dde71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading classes:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÅ about: 8 valid samples\n",
      "  üìÅ accident: 13 valid samples\n",
      "  üìÅ africa: 13 valid samples\n",
      "  üìÅ again: 10 valid samples\n",
      "  üìÅ again: 10 valid samples\n",
      "  üìÅ all: 13 valid samples\n",
      "  üìÅ always: 9 valid samples\n",
      "  üìÅ animal: 10 valid samples\n",
      "  üìÅ apple: 13 valid samples\n",
      "  üìÅ all: 13 valid samples\n",
      "  üìÅ always: 9 valid samples\n",
      "  üìÅ animal: 10 valid samples\n",
      "  üìÅ apple: 13 valid samples\n",
      "  üìÅ approve: 11 valid samples\n",
      "  üìÅ approve: 11 valid samples\n",
      "  üìÅ argue: 10 valid samples\n",
      "  üìÅ arrive: 10 valid samples\n",
      "  üìÅ baby: 10 valid samples\n",
      "  üìÅ back: 7 valid samples\n",
      "  üìÅ backpack: 11 valid samples\n",
      "  üìÅ bad: 11 valid samples\n",
      "  üìÅ argue: 10 valid samples\n",
      "  üìÅ arrive: 10 valid samples\n",
      "  üìÅ baby: 10 valid samples\n",
      "  üìÅ back: 7 valid samples\n",
      "  üìÅ backpack: 11 valid samples\n",
      "  üìÅ bad: 11 valid samples\n",
      "  üìÅ bake: 8 valid samples\n",
      "  üìÅ bake: 8 valid samples\n",
      "  üìÅ balance: 11 valid samples\n",
      "  üìÅ ball: 11 valid samples\n",
      "  üìÅ banana: 10 valid samples\n",
      "  üìÅ bar: 10 valid samples\n",
      "  üìÅ basketball: 12 valid samples\n",
      "  üìÅ balance: 11 valid samples\n",
      "  üìÅ ball: 11 valid samples\n",
      "  üìÅ banana: 10 valid samples\n",
      "  üìÅ bar: 10 valid samples\n",
      "  üìÅ basketball: 12 valid samples\n",
      "  üìÅ bath: 10 valid samples\n",
      "  üìÅ bath: 10 valid samples\n",
      "  üìÅ bathroom: 10 valid samples\n",
      "  üìÅ beard: 10 valid samples\n",
      "  üìÅ because: 7 valid samples\n",
      "  üìÅ bed: 13 valid samples\n",
      "  üìÅ before: 17 valid samples\n",
      "  üìÅ bathroom: 10 valid samples\n",
      "  üìÅ beard: 10 valid samples\n",
      "  üìÅ because: 7 valid samples\n",
      "  üìÅ bed: 13 valid samples\n",
      "  üìÅ before: 17 valid samples\n",
      "  üìÅ behind: 9 valid samples  üìÅ behind: 9 valid samples\n",
      "  üìÅ bird: 12 valid samples\n",
      "  üìÅ birthday: 9 valid samples\n",
      "  üìÅ black: 13 valid samples\n",
      "  üìÅ blanket: 8 valid samples\n",
      "  üìÅ blue: 12 valid samples\n",
      "\n",
      "  üìÅ bird: 12 valid samples\n",
      "  üìÅ birthday: 9 valid samples\n",
      "  üìÅ black: 13 valid samples\n",
      "  üìÅ blanket: 8 valid samples\n",
      "  üìÅ blue: 12 valid samples\n",
      "  üìÅ book: 10 valid samples\n",
      "  üìÅ bowling: 13 valid samples\n",
      "  üìÅ boy: 10 valid samples\n",
      "  üìÅ bring: 10 valid samples\n",
      "  üìÅ brother: 11 valid samples\n",
      "  üìÅ brown: 11 valid samples\n",
      "  üìÅ book: 10 valid samples\n",
      "  üìÅ bowling: 13 valid samples\n",
      "  üìÅ boy: 10 valid samples\n",
      "  üìÅ bring: 10 valid samples\n",
      "  üìÅ brother: 11 valid samples\n",
      "  üìÅ brown: 11 valid samples\n",
      "  üìÅ business: 11 valid samples\n",
      "  üìÅ but: 10 valid samples\n",
      "  üìÅ buy: 11 valid samples\n",
      "  üìÅ call: 11 valid samples\n",
      "  üìÅ can: 12 valid samples\n",
      "  üìÅ business: 11 valid samples\n",
      "  üìÅ but: 10 valid samples\n",
      "  üìÅ buy: 11 valid samples\n",
      "  üìÅ call: 11 valid samples\n",
      "  üìÅ can: 12 valid samples\n",
      "  üìÅ candy: 14 valid samples\n",
      "  üìÅ careful: 8 valid samples\n",
      "  üìÅ cat: 11 valid samples\n",
      "  üìÅ catch: 9 valid samples\n",
      "  üìÅ center: 10 valid samples\n",
      "  üìÅ cereal: 9 valid samples\n",
      "  üìÅ candy: 14 valid samples\n",
      "  üìÅ careful: 8 valid samples\n",
      "  üìÅ cat: 11 valid samples\n",
      "  üìÅ catch: 9 valid samples\n",
      "  üìÅ center: 10 valid samples\n",
      "  üìÅ cereal: 9 valid samples\n",
      "  üìä Total samples: 532\n",
      "  üìä Total classes: 50\n",
      "  ‚úÖ Test split: 107 samples\n",
      "‚úÖ Datasets created successfully!\n",
      "üìä Training samples: 425\n",
      "üìä Validation samples: 53\n",
      "üìä Test samples: 54\n",
      "üìä Number of classes: 50\n",
      "üíæ Class mapping saved to f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints/class_mapping.json\n",
      "\n",
      "üß™ Testing data loader...\n",
      "  üìä Total samples: 532\n",
      "  üìä Total classes: 50\n",
      "  ‚úÖ Test split: 107 samples\n",
      "‚úÖ Datasets created successfully!\n",
      "üìä Training samples: 425\n",
      "üìä Validation samples: 53\n",
      "üìä Test samples: 54\n",
      "üìä Number of classes: 50\n",
      "üíæ Class mapping saved to f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints/class_mapping.json\n",
      "\n",
      "üß™ Testing data loader...\n",
      "  Batch data shape: torch.Size([12, 50, 553, 3])\n",
      "  Batch targets shape: torch.Size([12])\n",
      "  Data type: torch.float32\n",
      "  Target range: 2 to 48\n",
      "  Batch data shape: torch.Size([12, 50, 553, 3])\n",
      "  Batch targets shape: torch.Size([12])\n",
      "  Data type: torch.float32\n",
      "  Target range: 2 to 48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data paths and directories\n",
    "DATA_DIR = r'f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\data\\keypoints'\n",
    "CHECKPOINT_DIR = r'f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints'\n",
    "MODEL_SAVE_PATH = os.path.join(CHECKPOINT_DIR, 'best_transformer_model.pth')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Fix the dataset creation logic\n",
    "print(\"üîÑ Creating enhanced datasets with proper train/val/test splits...\")\n",
    "\n",
    "# Create normalizer\n",
    "normalizer = SimpleNormalizer()\n",
    "\n",
    "# First, create a temporary dataset to get all data and fit normalizer\n",
    "temp_dataset = ASLKeypointDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    max_seq_len=CONFIG['max_seq_len'],\n",
    "    split='train',  # Get training portion for normalization\n",
    "    test_size=CONFIG['test_size'],\n",
    "    random_state=42,\n",
    "    use_subset=True,\n",
    "    max_classes=CONFIG['max_classes'],\n",
    "    normalizer=None,\n",
    "    use_augmentation=False\n",
    ")\n",
    "\n",
    "# Fit normalizer on training data\n",
    "print(\"üîß Fitting normalizer on training data...\")\n",
    "normalizer.fit([temp_dataset.data[i] for i in range(len(temp_dataset.data))])\n",
    "\n",
    "# Now create the actual datasets with proper splits\n",
    "# Create training dataset\n",
    "train_dataset = ASLKeypointDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    max_seq_len=CONFIG['max_seq_len'],\n",
    "    split='train',\n",
    "    test_size=CONFIG['test_size'],\n",
    "    random_state=42,\n",
    "    use_subset=True,\n",
    "    max_classes=CONFIG['max_classes'],\n",
    "    normalizer=normalizer,\n",
    "    use_augmentation=CONFIG['use_augmentation']\n",
    ")\n",
    "\n",
    "# Create test dataset (this will be our validation set)\n",
    "test_dataset = ASLKeypointDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    max_seq_len=CONFIG['max_seq_len'],\n",
    "    split='test',  # This gives us the test portion\n",
    "    test_size=CONFIG['test_size'],\n",
    "    random_state=42,\n",
    "    use_subset=True,\n",
    "    max_classes=CONFIG['max_classes'],\n",
    "    normalizer=normalizer,\n",
    "    use_augmentation=False\n",
    ")\n",
    "\n",
    "# For validation, we'll use a portion of test data\n",
    "# Split test data into val and test\n",
    "val_size = len(test_dataset) // 2  # Use half for validation, half for testing\n",
    "test_size = len(test_dataset) - val_size\n",
    "\n",
    "val_dataset, final_test_dataset = random_split(\n",
    "    test_dataset, \n",
    "    [val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Datasets created successfully!\")\n",
    "print(f\"üìä Training samples: {len(train_dataset)}\")\n",
    "print(f\"üìä Validation samples: {len(val_dataset)}\")\n",
    "print(f\"üìä Test samples: {len(final_test_dataset)}\")\n",
    "print(f\"üìä Number of classes: {train_dataset.num_classes}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory'] if torch.cuda.is_available() else False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory'] if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    final_test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory'] if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Get class names from training dataset\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Save class mapping\n",
    "class_mapping = {\n",
    "    'word_to_idx': train_dataset.word_to_idx,\n",
    "    'idx_to_word': train_dataset.idx_to_word,\n",
    "    'class_names': train_dataset.class_names\n",
    "}\n",
    "\n",
    "with open(os.path.join(CHECKPOINT_DIR, 'class_mapping.json'), 'w') as f:\n",
    "    json.dump(class_mapping, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Class mapping saved to {CHECKPOINT_DIR}/class_mapping.json\")\n",
    "\n",
    "# Test data loader\n",
    "print(\"\\nüß™ Testing data loader...\")\n",
    "test_batch = next(iter(train_loader))\n",
    "test_data, test_targets = test_batch\n",
    "print(f\"  Batch data shape: {test_data.shape}\")\n",
    "print(f\"  Batch targets shape: {test_targets.shape}\")\n",
    "print(f\"  Data type: {test_data.dtype}\")\n",
    "print(f\"  Target range: {test_targets.min().item()} to {test_targets.max().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1fb46",
   "metadata": {},
   "source": [
    "## üöÄ Ultra-Optimized Model Initialization and Training Setup\n",
    "\n",
    "Initialize the Transformer model with all GPU optimizations and training enhancements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27e2b950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Ultra-Optimized Transformer Model\n",
      "============================================================\n",
      "üèóÔ∏è Model Architecture:\n",
      "  Input dimension: 1659\n",
      "  Model dimension: 160\n",
      "  Attention heads: 10\n",
      "  Transformer layers: 8\n",
      "  Output classes: 50\n",
      "  Total parameters: 2,756,770\n",
      "  Trainable parameters: 2,756,770\n",
      "  Model size: 10.52 MB\n",
      "‚úÖ Mixed precision training enabled\n",
      "\n",
      "‚öôÔ∏è Training Configuration:\n",
      "  Device: cuda\n",
      "  Optimizer: AdamW with OneCycleLR\n",
      "  Loss: CrossEntropyLoss with label smoothing\n",
      "  Mixed precision: True\n",
      "  Data augmentation: True\n",
      "  Batch size: 12\n",
      "  Max epochs: 100\n",
      "\n",
      "üß™ Testing model forward pass...\n",
      "  Input shape: torch.Size([2, 50, 553, 3])\n",
      "  Reshaped input: torch.Size([2, 50, 1659])\n",
      "  Output shape: torch.Size([2, 50])\n",
      "  Expected output: [2, 50]\n",
      "  ‚úÖ Forward pass successful!\n",
      "============================================================\n",
      "üéØ Ready for ultra-optimized training!\n"
     ]
    }
   ],
   "source": [
    "# Add the missing comprehensive_evaluation function\n",
    "def comprehensive_evaluation(model, data_loader, device, class_names):\n",
    "    \"\"\"Comprehensive model evaluation with detailed metrics\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    print(\"üîÑ Running comprehensive evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(tqdm(data_loader, desc=\"Evaluating\")):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # Handle data reshaping for transformer input\n",
    "            if len(data.shape) == 4:  # (batch, seq_len, nodes, features)\n",
    "                batch_size, seq_len, num_nodes, num_features = data.shape\n",
    "                data = data.view(batch_size, seq_len, num_nodes * num_features)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            num_batches += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(\n",
    "        all_targets, all_predictions, \n",
    "        target_names=class_names, \n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\nüìä Evaluation Results:\")\n",
    "    print(f\"  üéØ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"  üìà Macro F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
    "    print(f\"  üìä Weighted F1-Score: {report['weighted avg']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Print per-class results (first 10 classes)\n",
    "    print(f\"\\nüìã Per-Class Performance (Top 10):\")\n",
    "    print(f\"{'Class':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names[:10]):\n",
    "        if class_name in report:\n",
    "            p = report[class_name]['precision']\n",
    "            r = report[class_name]['recall']\n",
    "            f1 = report[class_name]['f1-score']\n",
    "            print(f\"{class_name:<15} {p:<10.3f} {r:<10.3f} {f1:<10.3f}\")\n",
    "    \n",
    "    if len(class_names) > 10:\n",
    "        print(f\"... and {len(class_names) - 10} more classes\")\n",
    "    \n",
    "    return accuracy, report\n",
    "\n",
    "print(\"üöÄ Initializing Ultra-Optimized Transformer Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get input dimension from CONFIG (already calculated)\n",
    "input_dim = CONFIG['input_dim']\n",
    "\n",
    "# Initialize model\n",
    "model = TransformerASL(\n",
    "    input_dim=input_dim,\n",
    "    d_model=CONFIG['d_model'],\n",
    "    nhead=CONFIG['nhead'],\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    num_classes=train_dataset.num_classes,\n",
    "    seq_len=CONFIG['max_seq_len'],\n",
    "    dropout=CONFIG['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"üèóÔ∏è Model Architecture:\")\n",
    "print(f\"  Input dimension: {input_dim}\")\n",
    "print(f\"  Model dimension: {CONFIG['d_model']}\")\n",
    "print(f\"  Attention heads: {CONFIG['nhead']}\")\n",
    "print(f\"  Transformer layers: {CONFIG['num_layers']}\")\n",
    "print(f\"  Output classes: {train_dataset.num_classes}\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=CONFIG['learning_rate'],\n",
    "    epochs=CONFIG['num_epochs'],\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "# Initialize mixed precision scaler if enabled\n",
    "scaler = None\n",
    "if CONFIG['use_mixed_precision'] and torch.cuda.is_available():\n",
    "    scaler = GradScaler()\n",
    "    print(f\"‚úÖ Mixed precision training enabled\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  Optimizer: AdamW with OneCycleLR\")\n",
    "print(f\"  Loss: CrossEntropyLoss with label smoothing\")\n",
    "print(f\"  Mixed precision: {CONFIG['use_mixed_precision']}\")\n",
    "print(f\"  Data augmentation: {CONFIG['use_augmentation']}\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Max epochs: {CONFIG['num_epochs']}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\nüß™ Testing model forward pass...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(train_loader))\n",
    "    test_data, test_targets = test_batch[0][:2].to(device), test_batch[1][:2].to(device)\n",
    "    \n",
    "    # Reshape for transformer\n",
    "    batch_size, seq_len, num_nodes, num_features = test_data.shape\n",
    "    test_data_reshaped = test_data.view(batch_size, seq_len, num_nodes * num_features)\n",
    "    \n",
    "    test_output = model(test_data_reshaped)\n",
    "    print(f\"  Input shape: {test_data.shape}\")\n",
    "    print(f\"  Reshaped input: {test_data_reshaped.shape}\")\n",
    "    print(f\"  Output shape: {test_output.shape}\")\n",
    "    print(f\"  Expected output: [2, {train_dataset.num_classes}]\")\n",
    "    \n",
    "    if test_output.shape == (2, train_dataset.num_classes):\n",
    "        print(f\"  ‚úÖ Forward pass successful!\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Shape mismatch in forward pass!\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Ready for ultra-optimized training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfbaf22",
   "metadata": {},
   "source": [
    "## üöÄ Ultra-Optimized Training Pipeline\n",
    "\n",
    "Implementing the complete ultra-optimized training pipeline with all advanced features from TGCN pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "280e57fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "üî• Initializing Ultra-Optimized Training Pipeline...\n",
      "üöÄ Starting Ultra-Optimized Training Pipeline...\n",
      "üìä Configuration: 50 classes, 100 epochs\n",
      "‚öôÔ∏è  Mixed Precision: True\n",
      "üíæ Checkpointing: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3763c2d52974ea7ae4d1794bc707c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üèãÔ∏è  Training Progress:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c02b6f376e4720a5156fa84b7397c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3827f82ee7394e879f5fe36995a56aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   1/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.9204, Acc=1.67%\n",
      "  üîç Val:   Loss=3.9060, Acc=0.00%\n",
      "  ‚ö° Speed: 231 samples/sec, Time: 2.0s\n",
      "  üìö LR: 1.20e-05, Best Val Acc: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fe88b926d4460e8e70a50846edd611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf1a89e478f4b8d836e2c6b75f26a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   2/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.8970, Acc=2.62%\n",
      "  üîç Val:   Loss=3.8922, Acc=1.67%\n",
      "  ‚ö° Speed: 247 samples/sec, Time: 1.8s\n",
      "  üìö LR: 1.20e-05, Best Val Acc: 1.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f862946c0ea8493ca708297a1ab7a92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ae2071a32f4c7abfb17ad51f8c4986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   3/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.8756, Acc=3.81%\n",
      "  üîç Val:   Loss=3.9047, Acc=1.67%\n",
      "  ‚ö° Speed: 279 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.21e-05, Best Val Acc: 1.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634cab892e4a4ecfa80f0702e1f563da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8309cbdb42964fed9c03c4f67f6ab678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   4/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.8591, Acc=3.57%\n",
      "  üîç Val:   Loss=3.8962, Acc=3.33%\n",
      "  ‚ö° Speed: 286 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.21e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b45c5ca0c99495fb8b01068d16d1d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c724b1f5a0084ac49fae004c0eb2215c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   5/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.8411, Acc=3.81%\n",
      "  üîç Val:   Loss=3.8937, Acc=3.33%\n",
      "  ‚ö° Speed: 258 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.21e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44e825f20064db397ea9d190e484c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf44871ad9a4562b00dbab16c0f9f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   6/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.8368, Acc=5.48%\n",
      "  üîç Val:   Loss=3.8699, Acc=3.33%\n",
      "  ‚ö° Speed: 271 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.22e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23424a7d21084ee98dffd0a6938b8f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a73ff86e58d42e1a70a6eb8ae6f15dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   7/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.8159, Acc=3.81%\n",
      "  üîç Val:   Loss=3.8717, Acc=3.33%\n",
      "  ‚ö° Speed: 259 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.23e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c107588ad6ff49159abec501eac9c341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca812a05c2e4489a7dabb39e80cd7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   8/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7844, Acc=5.00%\n",
      "  üîç Val:   Loss=3.8684, Acc=3.33%\n",
      "  ‚ö° Speed: 269 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.24e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a85a5c80a0342ae9f8d3538d1246b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b9a475c6cf4c5e8c7b89c125accd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch   9/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7639, Acc=6.67%\n",
      "  üîç Val:   Loss=3.8519, Acc=3.33%\n",
      "  ‚ö° Speed: 284 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.25e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f02e5e5aef4fe6825bc2e66ffd2a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350802cb14fe47ac9e4714e1e8aadf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  10/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7535, Acc=6.90%\n",
      "  üîç Val:   Loss=3.8511, Acc=1.67%\n",
      "  ‚ö° Speed: 279 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.26e-05, Best Val Acc: 3.33%\n",
      "  üíæ Checkpoint saved: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints\\checkpoint_epoch_10.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b52197cb274b0b85d0c40f7b963f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9c2d1533364bcdab077d2b773bcf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  11/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7405, Acc=5.00%\n",
      "  üîç Val:   Loss=3.8450, Acc=1.67%\n",
      "  ‚ö° Speed: 289 samples/sec, Time: 1.5s\n",
      "  üìö LR: 1.27e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3713251fb8b84aeea92cbbad7ca8b7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4baa1cb10f4c71a0c8fd977f41228e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  12/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7268, Acc=6.67%\n",
      "  üîç Val:   Loss=3.8360, Acc=3.33%\n",
      "  ‚ö° Speed: 248 samples/sec, Time: 1.8s\n",
      "  üìö LR: 1.28e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5545e5f8f390427b995f00af1200dd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57863cbcb6644333be4e91a6d4f5a04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  13/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7099, Acc=7.14%\n",
      "  üîç Val:   Loss=3.8246, Acc=3.33%\n",
      "  ‚ö° Speed: 274 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.30e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefa1aeb5d2b436badc230e43a023e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726fe4cfc966411aa552a1c1ff9855ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  14/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7060, Acc=7.86%\n",
      "  üîç Val:   Loss=3.8428, Acc=3.33%\n",
      "  ‚ö° Speed: 270 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.31e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b142502e474748b1f71705a36bc689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba88cb9baef4e0ab19373fe0e6d836c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  15/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.7078, Acc=8.81%\n",
      "  üîç Val:   Loss=3.8181, Acc=3.33%\n",
      "  ‚ö° Speed: 275 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.33e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1fb1c8ac144346af175e01f18947e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaa2f69d2894ff383673f8346dadddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  16/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6771, Acc=6.19%\n",
      "  üîç Val:   Loss=3.8157, Acc=3.33%\n",
      "  ‚ö° Speed: 293 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.35e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a2f89a89cc448aa55b7b2fac8cec5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38454546d696489abdd98cb9d57d3e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  17/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6724, Acc=8.33%\n",
      "  üîç Val:   Loss=3.8179, Acc=3.33%\n",
      "  ‚ö° Speed: 285 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.37e-05, Best Val Acc: 3.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170aacd9ed9f4824b9b0c6e8bb773c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0cccb07d134164939bb8d1350729b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  18/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6590, Acc=7.86%\n",
      "  üîç Val:   Loss=3.8130, Acc=9.00%\n",
      "  ‚ö° Speed: 280 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.39e-05, Best Val Acc: 9.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68812bb6d0d942899733cbbf7e7ff064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6fba087eac4a5ba627ab1bda7b5fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  19/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6529, Acc=8.10%\n",
      "  üîç Val:   Loss=3.7976, Acc=5.00%\n",
      "  ‚ö° Speed: 288 samples/sec, Time: 1.5s\n",
      "  üìö LR: 1.41e-05, Best Val Acc: 9.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b8bda6b2c948958488e4688e0eae92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba2a9cbc0604cddb5ce4dc9e868fcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  20/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6375, Acc=8.81%\n",
      "  üîç Val:   Loss=3.8000, Acc=7.33%\n",
      "  ‚ö° Speed: 278 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.43e-05, Best Val Acc: 9.00%\n",
      "  üíæ Checkpoint saved: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints\\checkpoint_epoch_20.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a859a483b9407e8f61437956915318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40963e164264e449c99e381df9add25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  21/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6339, Acc=10.24%\n",
      "  üîç Val:   Loss=3.7942, Acc=9.00%\n",
      "  ‚ö° Speed: 274 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.46e-05, Best Val Acc: 9.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a727fc8305340588c44becadb599e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39ff03d8d6c413a8a0440ee12de7190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  22/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6074, Acc=11.90%\n",
      "  üîç Val:   Loss=3.7888, Acc=5.00%\n",
      "  ‚ö° Speed: 287 samples/sec, Time: 1.5s\n",
      "  üìö LR: 1.48e-05, Best Val Acc: 9.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e59312b37714d69b4a0b0a3ac03c479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12e3af8d16e4c9095962dfd50162c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  23/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.6127, Acc=9.76%\n",
      "  üîç Val:   Loss=3.8025, Acc=8.33%\n",
      "  ‚ö° Speed: 280 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.51e-05, Best Val Acc: 9.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042a26fb568c45b6b053b5a82afaab21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a2ef9657624061947066f730af6ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  24/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.5861, Acc=11.90%\n",
      "  üîç Val:   Loss=3.7739, Acc=10.67%\n",
      "  ‚ö° Speed: 274 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.53e-05, Best Val Acc: 10.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f759285b86483da50acd8f21924656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6b41b4f8d44e25a81da63c8a00cc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  25/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.5773, Acc=11.19%\n",
      "  üîç Val:   Loss=3.7943, Acc=6.67%\n",
      "  ‚ö° Speed: 274 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.56e-05, Best Val Acc: 10.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b806e1677334004a129fde3074b5f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cae14ad172943678607bc3a18cbf873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  26/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.5609, Acc=13.57%\n",
      "  üîç Val:   Loss=3.7721, Acc=12.33%\n",
      "  ‚ö° Speed: 264 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.59e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d3c2ea6f43479da91b0777787d415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e329af91bb2473d88be4b968ef1e080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  27/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.5534, Acc=12.86%\n",
      "  üîç Val:   Loss=3.7992, Acc=3.33%\n",
      "  ‚ö° Speed: 269 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.62e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab57e9e0b1d4151a00320f1bb8d2bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757cff82e18d416998107a19318a474b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  28/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.5466, Acc=14.29%\n",
      "  üîç Val:   Loss=3.7584, Acc=10.67%\n",
      "  ‚ö° Speed: 283 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.65e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c1a692a0ea4c78a22222c44495a733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba837f116fb497aa4e9bb57fea00e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  29/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.5184, Acc=14.76%\n",
      "  üîç Val:   Loss=3.7745, Acc=9.00%\n",
      "  ‚ö° Speed: 281 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.69e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9e631ca8d3473291fa4ce9e63c1c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3ba1d4e58343f98ee548ecfa8f584a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  30/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.5101, Acc=15.95%\n",
      "  üîç Val:   Loss=3.7830, Acc=9.00%\n",
      "  ‚ö° Speed: 285 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.72e-05, Best Val Acc: 12.33%\n",
      "  üíæ Checkpoint saved: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints\\checkpoint_epoch_30.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e633db6f673c4636bf2f9c30935c9ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2de947bd1a4a4d882ce05d6d974bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  31/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.4794, Acc=17.38%\n",
      "  üîç Val:   Loss=3.7680, Acc=10.67%\n",
      "  ‚ö° Speed: 265 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.76e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f839755e8a4410a73d7d17e1963bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff026eb9d084ec3ac8564bd58ffd8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  32/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.4987, Acc=17.14%\n",
      "  üîç Val:   Loss=3.7591, Acc=10.67%\n",
      "  ‚ö° Speed: 278 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.79e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5580c4689d16459f85ac8704e025cd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e29700111b4967bb9ca9d7196bc472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  33/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.4715, Acc=15.24%\n",
      "  üîç Val:   Loss=3.7593, Acc=10.67%\n",
      "  ‚ö° Speed: 273 samples/sec, Time: 1.6s\n",
      "  üìö LR: 1.83e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df70faee663c4308ba19b90707191214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18a9f8f6b194f028570081ef7296b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîç Validation:   0%|          | 0/5 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Epoch  34/100 Summary:\n",
      "  üèãÔ∏è  Train: Loss=3.4465, Acc=18.57%\n",
      "  üîç Val:   Loss=3.7454, Acc=9.00%\n",
      "  ‚ö° Speed: 269 samples/sec, Time: 1.7s\n",
      "  üìö LR: 1.87e-05, Best Val Acc: 12.33%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e04cbaec5e4130a6325f01bbe0ef64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müî• Initializing Ultra-Optimized Training Pipeline...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Run the training pipeline\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m training_metrics, final_best_acc \u001b[38;5;241m=\u001b[39m \u001b[43multra_optimized_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müèÜ Training Pipeline Completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä Final Best Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_best_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[46], line 48\u001b[0m, in \u001b[0;36multra_optimized_training_pipeline\u001b[1;34m(model, train_loader, val_loader, optimizer, scheduler, scaler, criterion, device, config, class_names)\u001b[0m\n\u001b[0;32m     45\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Training phase - Fixed parameter passing\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m train_loss, train_acc, train_speed \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch_with_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_mixed_precision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Validation phase  \u001b[39;00m\n\u001b[0;32m     53\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate_epoch_with_progress(\n\u001b[0;32m     54\u001b[0m     model, val_loader, criterion, device)\n",
      "Cell \u001b[1;32mIn[43], line 140\u001b[0m, in \u001b[0;36mtrain_epoch_with_progress\u001b[1;34m(model, train_loader, criterion, optimizer, device, use_mixed_precision, scaler)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_mixed_precision \u001b[38;5;129;01mand\u001b[39;00m scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m--> 140\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m    143\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[42], line 53\u001b[0m, in \u001b[0;36mTransformerASL.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Create padding mask\u001b[39;00m\n\u001b[0;32m     51\u001b[0m src_key_padding_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Global average pooling\u001b[39;00m\n\u001b[0;32m     56\u001b[0m mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m~\u001b[39msrc_key_padding_mask)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:514\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    511\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 514\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    522\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:914\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    910\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    912\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m    913\u001b[0m         x\n\u001b[1;32m--> 914\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    915\u001b[0m     )\n\u001b[0;32m    916\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:928\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    923\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    926\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    927\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 928\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1347\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1348\u001b[0m         query,\n\u001b[0;32m   1349\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1373\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:6230\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   6226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[0;32m   6227\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m   6228\u001b[0m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6229\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 6230\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6232\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m   6233\u001b[0m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6234\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:5614\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[1;34m(q, k, v, w, b)\u001b[0m\n\u001b[0;32m   5611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m v:\n\u001b[0;32m   5612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[0;32m   5613\u001b[0m         \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[1;32m-> 5614\u001b[0m         proj \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5615\u001b[0m         \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[0;32m   5616\u001b[0m         proj \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   5617\u001b[0m             proj\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m3\u001b[39m, E))\n\u001b[0;32m   5618\u001b[0m             \u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5621\u001b[0m             \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m   5622\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_val_acc = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "def ultra_optimized_training_pipeline(model, train_loader, val_loader, \n",
    "                                      optimizer, scheduler, scaler, criterion,\n",
    "                                      device, config, class_names):\n",
    "    \"\"\"\n",
    "    Ultra-optimized training pipeline with all advanced features:\n",
    "    - Mixed precision training\n",
    "    - Progress bars with detailed metrics\n",
    "    - Model checkpointing\n",
    "    - Advanced learning rate scheduling\n",
    "    - Comprehensive metrics tracking\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting Ultra-Optimized Training Pipeline...\")\n",
    "    print(f\"üìä Configuration: {len(class_names)} classes, {config['num_epochs']} epochs\")\n",
    "    print(f\"‚öôÔ∏è  Mixed Precision: {config['use_mixed_precision']}\")\n",
    "    print(f\"üíæ Checkpointing: {config['save_checkpoints']}\")\n",
    "    \n",
    "    # Initialize metrics tracker\n",
    "    metrics = MetricsTracker()\n",
    "    \n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = config.get('checkpoint_dir', 'checkpoints')\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Training loop with progress tracking\n",
    "    best_val_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    # Main training epochs with tqdm\n",
    "    epoch_pbar = trange(config['num_epochs'], desc=\"üèãÔ∏è  Training Progress\", \n",
    "                       unit=\"epoch\", position=0)\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase - Fixed parameter passing\n",
    "        train_loss, train_acc, train_speed = train_epoch_with_progress(\n",
    "            model, train_loader, criterion, optimizer, device, \n",
    "            config['use_mixed_precision'], scaler)\n",
    "        \n",
    "        # Validation phase  \n",
    "        val_loss, val_acc = validate_epoch_with_progress(\n",
    "            model, val_loader, criterion, device)\n",
    "        \n",
    "        \n",
    "        # Scheduler step\n",
    "        if config['scheduler_type'] == 'ReduceLROnPlateau':\n",
    "            scheduler.step(val_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Calculate epoch time and speed\n",
    "        epoch_time = time.time() - start_time\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Update metrics\n",
    "        metrics.update(train_loss, train_acc, val_loss, val_acc, current_lr, \n",
    "                      epoch_time, train_speed)\n",
    "        \n",
    "        # Check for best model\n",
    "        is_best = val_acc > best_val_acc\n",
    "        if is_best:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_without_improvement = 0\n",
    "            \n",
    "            # Save best model\n",
    "            if config['save_checkpoints']:\n",
    "                best_model_path = os.path.join(checkpoint_dir, 'best_transformer_model.pth')\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                    'val_acc': val_acc,\n",
    "                    'train_acc': train_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'train_loss': train_loss,\n",
    "                    'class_names': class_names,\n",
    "                    'config': config\n",
    "                }, best_model_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Update progress bar description\n",
    "        epoch_pbar.set_postfix({\n",
    "            'Train_Acc': f'{train_acc:.1f}%',\n",
    "            'Val_Acc': f'{val_acc:.1f}%', \n",
    "            'Best_Val': f'{best_val_acc:.1f}%',\n",
    "            'LR': f'{current_lr:.2e}',\n",
    "            'Speed': f'{train_speed:.0f} smp/s'\n",
    "        })\n",
    "        \n",
    "        # Detailed epoch summary\n",
    "        print(f\"\\nüìà Epoch {epoch+1:3d}/{config['num_epochs']} Summary:\")\n",
    "        print(f\"  üèãÔ∏è  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "        print(f\"  üîç Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
    "        print(f\"  ‚ö° Speed: {train_speed:.0f} samples/sec, Time: {epoch_time:.1f}s\")\n",
    "        print(f\"  üìö LR: {current_lr:.2e}, Best Val Acc: {best_val_acc:.2f}%\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epochs_without_improvement >= config['patience']:\n",
    "            print(f\"\\nüõë Early stopping triggered after {epochs_without_improvement} epochs without improvement\")\n",
    "            break\n",
    "        \n",
    "        # Periodic checkpoint saving\n",
    "        if config['save_checkpoints'] and (epoch + 1) % config.get('checkpoint_frequency', 10) == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'metrics': metrics,\n",
    "                'config': config\n",
    "            }, checkpoint_path)\n",
    "            print(f\"  üíæ Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Training completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # Plot final metrics\n",
    "    print(\"\\nüìä Generating training visualizations...\")\n",
    "    metrics.plot_metrics()\n",
    "    \n",
    "    return metrics, best_val_acc\n",
    "\n",
    "# Execute ultra-optimized training\n",
    "print(\"üî• Initializing Ultra-Optimized Training Pipeline...\")\n",
    "\n",
    "# Run the training pipeline\n",
    "training_metrics, final_best_acc = ultra_optimized_training_pipeline(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader, \n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    scaler=scaler,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    config=CONFIG,\n",
    "    class_names=class_names\n",
    ")\n",
    "\n",
    "print(f\"\\nüèÜ Training Pipeline Completed!\")\n",
    "print(f\"üìä Final Best Validation Accuracy: {final_best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8cfee",
   "metadata": {},
   "source": [
    "## üéØ Ultra-Comprehensive Model Evaluation\n",
    "\n",
    "Loading best model and performing detailed evaluation with advanced metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb498c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading best model from: f:\\Uni_Stuff\\6th_Sem\\DL\\Proj\\video-asl-recognition\\pose_estimation\\src\\checkpoints\\best_transformer_model.pth\n",
      "‚úÖ Model loaded successfully!\n",
      "  üìä Best epoch: 14\n",
      "  üéØ Best validation accuracy: 8.33%\n",
      "  üèãÔ∏è  Training accuracy: 9.80%\n",
      "\n",
      "üîç Starting comprehensive model evaluation...\n",
      "\n",
      "üìä Validation Set Evaluation:\n",
      "üîÑ Running comprehensive evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c523784e4f4e17bf8eb1490b011c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 43, does not match size of target_names, 50. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Test the model on validation set (since we used it for model selection)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Validation Set Evaluation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m val_accuracy, val_report \u001b[38;5;241m=\u001b[39m \u001b[43mcomprehensive_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# If test loader is available, evaluate on test set\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loader\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m test_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[35], line 32\u001b[0m, in \u001b[0;36mcomprehensive_evaluation\u001b[1;34m(model, data_loader, device, class_names)\u001b[0m\n\u001b[0;32m     29\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(all_targets, all_predictions)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Generate classification report\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Print detailed results\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Evaluation Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\aslpose\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\aslpose\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2693\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2687\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2689\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2690\u001b[0m             )\n\u001b[0;32m   2691\u001b[0m         )\n\u001b[0;32m   2692\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2694\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2697\u001b[0m         )\n\u001b[0;32m   2698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2699\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 43, does not match size of target_names, 50. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Load the best model checkpoint\n",
    "checkpoint_path = os.path.join(CONFIG.get('checkpoint_dir', 'checkpoints'), 'best_transformer_model.pth')\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"üì• Loading best model from: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"  üìä Best epoch: {checkpoint['epoch'] + 1}\")\n",
    "    print(f\"  üéØ Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "    print(f\"  üèãÔ∏è  Training accuracy: {checkpoint['train_acc']:.2f}%\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No checkpoint found at {checkpoint_path}, using current model state\")\n",
    "\n",
    "# Perform comprehensive evaluation\n",
    "print(\"\\nüîç Starting comprehensive model evaluation...\")\n",
    "\n",
    "# Test the model on validation set (since we used it for model selection)\n",
    "print(\"\\nüìä Validation Set Evaluation:\")\n",
    "val_accuracy, val_report = comprehensive_evaluation(model, val_loader, device, class_names)\n",
    "\n",
    "# If test loader is available, evaluate on test set\n",
    "if 'test_loader' in locals() and test_loader is not None:\n",
    "    print(\"\\nüß™ Test Set Evaluation:\")\n",
    "    test_accuracy, test_report = comprehensive_evaluation(model, test_loader, device, class_names)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Test loader not available, using validation set for final evaluation\")\n",
    "    test_accuracy = val_accuracy\n",
    "    test_report = val_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d5528",
   "metadata": {},
   "source": [
    "## üìà Detailed Performance Analysis\n",
    "\n",
    "Comprehensive analysis of model performance, efficiency, and insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5578ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional performance analysis\n",
    "print(\"\\nüî¨ Detailed Performance Analysis:\")\n",
    "\n",
    "# Model complexity analysis\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nüß† Model Architecture Analysis:\")\n",
    "print(f\"  üìä Total parameters: {total_params:,}\")\n",
    "print(f\"  üéØ Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  üíæ Model size: ~{total_params * 4 / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Training efficiency analysis\n",
    "if 'training_metrics' in locals():\n",
    "    avg_epoch_time = np.mean(training_metrics.epoch_times) if training_metrics.epoch_times else 0\n",
    "    avg_samples_per_sec = np.mean(training_metrics.samples_per_second) if training_metrics.samples_per_second else 0\n",
    "    \n",
    "    print(f\"\\n‚ö° Training Efficiency:\")\n",
    "    print(f\"  ‚è±Ô∏è  Average epoch time: {avg_epoch_time:.1f} seconds\")\n",
    "    print(f\"  üöÄ Average throughput: {avg_samples_per_sec:.0f} samples/second\")\n",
    "    print(f\"  üéØ Best validation accuracy: {training_metrics.best_val_acc:.2f}%\")\n",
    "    print(f\"  üìà Achieved at epoch: {training_metrics.best_epoch + 1}\")\n",
    "\n",
    "# Class distribution analysis\n",
    "if hasattr(train_dataset, 'labels'):\n",
    "    class_counts = np.bincount(train_dataset.labels)\n",
    "    print(f\"\\nüìä Dataset Class Distribution:\")\n",
    "    print(f\"  üìö Total classes: {len(class_names)}\")\n",
    "    print(f\"  üìù Total samples: {len(train_dataset)}\")\n",
    "    print(f\"  üìä Average samples per class: {len(train_dataset) / len(class_names):.1f}\")\n",
    "    print(f\"  üìâ Min samples in class: {class_counts.min()}\")\n",
    "    print(f\"  üìà Max samples in class: {class_counts.max()}\")\n",
    "\n",
    "# Performance comparison with configuration\n",
    "print(f\"\\n‚öôÔ∏è  Configuration Impact:\")\n",
    "print(f\"  üîß Mixed precision: {CONFIG['use_mixed_precision']}\")\n",
    "print(f\"  üì¶ Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  üß† Model dimension: {CONFIG['d_model']}\")\n",
    "print(f\"  üîÑ Transformer layers: {CONFIG['num_layers']}\")\n",
    "print(f\"  üéØ Attention heads: {CONFIG['nhead']}\")\n",
    "\n",
    "# Memory usage estimation\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    memory_allocated = torch.cuda.memory_allocated(device) / 1024**3  # GB\n",
    "    memory_reserved = torch.cuda.memory_reserved(device) / 1024**3   # GB\n",
    "    \n",
    "    print(f\"\\nüíæ GPU Memory Usage:\")\n",
    "    print(f\"  üìä Allocated: {memory_allocated:.2f} GB\")\n",
    "    print(f\"  üì¶ Reserved: {memory_reserved:.2f} GB\")\n",
    "    print(f\"  üéØ Device: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52ac11",
   "metadata": {},
   "source": [
    "## üìä Confusion Matrix and Class-wise Analysis\n",
    "\n",
    "Detailed confusion matrix and per-class performance analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "print(\"üîÑ Generating predictions for confusion matrix...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(val_loader, desc=\"Evaluating\")):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Handle data reshaping for transformer input\n",
    "        if len(data.shape) == 4:  # (batch, seq_len, nodes, features)\n",
    "            batch_size, seq_len, num_nodes, num_features = data.shape\n",
    "            data = data.view(batch_size, seq_len, num_nodes * num_features)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "if len(class_names) > 10:\n",
    "    # Show only first 10 classes for readability\n",
    "    cm_subset = cm[:10, :10]\n",
    "    class_subset = class_names[:10]\n",
    "    title = f\"Confusion Matrix (First 10 Classes out of {len(class_names)})\"\n",
    "else:\n",
    "    cm_subset = cm\n",
    "    class_subset = class_names\n",
    "    title = f\"Confusion Matrix (All {len(class_names)} Classes)\"\n",
    "\n",
    "sns.heatmap(cm_subset, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_subset, yticklabels=class_subset)\n",
    "plt.title(title, fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy analysis\n",
    "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "print(f\"\\nüìä Per-Class Accuracy Analysis:\")\n",
    "print(f\"{'Class':<15} {'Accuracy':<10} {'Support':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, (class_name, acc) in enumerate(zip(class_names, class_accuracies)):\n",
    "    support = cm.sum(axis=1)[i]\n",
    "    print(f\"{class_name:<15} {acc:<10.3f} {support:<10.0f}\")\n",
    "    if i >= 9:  # Show first 10 classes\n",
    "        break\n",
    "\n",
    "if len(class_names) > 10:\n",
    "    print(f\"... and {len(class_names) - 10} more classes\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"\\nüéØ Overall Accuracy: {overall_accuracy:.3f} ({overall_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bca5fb",
   "metadata": {},
   "source": [
    "## üèÜ Final Results Summary\n",
    "\n",
    "Comprehensive summary of the ultra-optimized ASL Transformer model performance and achievements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30596aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ ULTRA-OPTIMIZED ASL TRANSFORMER - FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Model Performance Summary\n",
    "print(f\"\\nüéØ MODEL PERFORMANCE:\")\n",
    "print(f\"  ü•á Best Validation Accuracy: {final_best_acc:.2f}%\")\n",
    "print(f\"  üîç Final Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "if 'test_report' in locals():\n",
    "    print(f\"  üìä Macro F1-Score: {test_report['macro avg']['f1-score']:.3f}\")\n",
    "    print(f\"  üìà Weighted F1-Score: {test_report['weighted avg']['f1-score']:.3f}\")\n",
    "\n",
    "# Architecture Summary\n",
    "print(f\"\\nüß† MODEL ARCHITECTURE:\")\n",
    "print(f\"  üîß Architecture: Transformer Encoder\")\n",
    "print(f\"  üìä Model Dimension: {CONFIG['d_model']}\")\n",
    "print(f\"  üîÑ Encoder Layers: {CONFIG['num_layers']}\")\n",
    "print(f\"  üéØ Attention Heads: {CONFIG['nhead']}\")\n",
    "print(f\"  üìù Total Parameters: {total_params:,}\")\n",
    "print(f\"  üéì Trainable Parameters: {trainable_params:,}\")\n",
    "\n",
    "# Dataset Summary\n",
    "print(f\"\\nüìö DATASET SUMMARY:\")\n",
    "print(f\"  üìä Total Classes: {len(class_names)}\")\n",
    "print(f\"  üìù Training Samples: {len(train_dataset)}\")\n",
    "print(f\"  üîç Validation Samples: {len(val_dataset)}\")\n",
    "print(f\"  üìè Sequence Length: {CONFIG['max_seq_len']}\")\n",
    "print(f\"  üéØ Input Features: {train_dataset[0][0].shape[-1]} per keypoint\")\n",
    "\n",
    "# Training Configuration\n",
    "print(f\"\\n‚öôÔ∏è  TRAINING CONFIGURATION:\")\n",
    "print(f\"  üî• Optimizer: {CONFIG['optimizer_type']}\")\n",
    "print(f\"  üìà Learning Rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  üì¶ Batch Size: {CONFIG['batch_size']}\")\n",
    "print(f\"  üîÑ Max Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"  ‚è±Ô∏è  Patience: {CONFIG['patience']}\")\n",
    "print(f\"  üéØ Mixed Precision: {CONFIG['use_mixed_precision']}\")\n",
    "\n",
    "# Performance Optimizations\n",
    "print(f\"\\nüöÄ PERFORMANCE OPTIMIZATIONS:\")\n",
    "print(f\"  ‚ö° GPU Acceleration: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  üéÆ GPU Device: {torch.cuda.get_device_name(device)}\")\n",
    "print(f\"  üîß Mixed Precision Training: {CONFIG['use_mixed_precision']}\")\n",
    "print(f\"  üìä Data Augmentation: {CONFIG.get('use_augmentation', False)}\")\n",
    "print(f\"  üíæ Model Checkpointing: {CONFIG['save_checkpoints']}\")\n",
    "print(f\"  üìà Progress Tracking: tqdm with detailed metrics\")\n",
    "\n",
    "# Training Efficiency\n",
    "if 'training_metrics' in locals() and training_metrics.epoch_times:\n",
    "    total_training_time = sum(training_metrics.epoch_times)\n",
    "    avg_epoch_time = np.mean(training_metrics.epoch_times)\n",
    "    avg_throughput = np.mean(training_metrics.samples_per_second) if training_metrics.samples_per_second else 0\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  TRAINING EFFICIENCY:\")\n",
    "    print(f\"  üïí Total Training Time: {total_training_time:.1f} seconds ({total_training_time/60:.1f} minutes)\")\n",
    "    print(f\"  üìä Average Epoch Time: {avg_epoch_time:.1f} seconds\")\n",
    "    if avg_throughput > 0:\n",
    "        print(f\"  üöÄ Average Throughput: {avg_throughput:.0f} samples/second\")\n",
    "    print(f\"  üéØ Epochs to Best Model: {training_metrics.best_epoch + 1}\")\n",
    "\n",
    "# Feature Highlights\n",
    "print(f\"\\n‚≠ê ADVANCED FEATURES IMPLEMENTED:\")\n",
    "print(f\"  üîÑ Positional Encoding for sequence modeling\")\n",
    "print(f\"  üéØ Multi-head Self-Attention mechanism\")\n",
    "print(f\"  üìä Advanced metrics tracking with visualizations\")\n",
    "print(f\"  üõ°Ô∏è  Gradient clipping for training stability\")\n",
    "print(f\"  üìà Learning rate scheduling (OneCycleLR)\")\n",
    "print(f\"  üîç Comprehensive evaluation with classification reports\")\n",
    "print(f\"  üíæ Automatic model checkpointing\")\n",
    "print(f\"  ‚ö° Mixed precision training for efficiency\")\n",
    "print(f\"  üìä Real-time progress monitoring with tqdm\")\n",
    "print(f\"  üõë Early stopping for optimal training\")\n",
    "\n",
    "# Key Improvements\n",
    "print(f\"\\nüîß KEY IMPROVEMENTS FROM BASIC VERSION:\")\n",
    "print(f\"  ‚úÖ Fixed 'nodes' vs 'pose' key compatibility\")\n",
    "print(f\"  ‚úÖ Enhanced normalization with robust statistics\")\n",
    "print(f\"  ‚úÖ Advanced training pipeline with mixed precision\")\n",
    "print(f\"  ‚úÖ Comprehensive metrics tracking and visualization\")\n",
    "print(f\"  ‚úÖ GPU optimization and memory efficiency\")\n",
    "print(f\"  ‚úÖ Professional-grade model checkpointing\")\n",
    "print(f\"  ‚úÖ Real-time progress monitoring\")\n",
    "print(f\"  ‚úÖ Advanced learning rate scheduling\")\n",
    "print(f\"  ‚úÖ Comprehensive evaluation framework\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"üéâ TRAINING COMPLETED SUCCESSFULLY! üéâ\")\n",
    "print(f\"Best model saved with {final_best_acc:.2f}% validation accuracy\")\n",
    "print(f\"All advanced features from TGCN pipeline successfully integrated!\")\n",
    "print(f\"Ultra-optimized ASL Transformer ready for deployment! üöÄ\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9eb18",
   "metadata": {},
   "source": [
    "## üíæ Model Export and Deployment Preparation\n",
    "\n",
    "Preparing the trained model for deployment and future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model state and metadata\n",
    "# Fix the deployment section to handle missing normalization stats gracefully\n",
    "# Save final model state and metadata\n",
    "print(\"üíæ Preparing model for deployment...\")\n",
    "\n",
    "# Create final model package\n",
    "final_model_path = os.path.join(CONFIG.get('checkpoint_dir', 'checkpoints'), 'asl_transformer_final.pth')\n",
    "\n",
    "# Safely get normalization stats\n",
    "normalization_stats = {}\n",
    "if hasattr(normalizer, 'mean') and normalizer.mean is not None:\n",
    "    normalization_stats['mean'] = normalizer.mean.tolist()\n",
    "if hasattr(normalizer, 'std') and normalizer.std is not None:\n",
    "    normalization_stats['std'] = normalizer.std.tolist()\n",
    "if hasattr(normalizer, 'center_x') and normalizer.center_x is not None:\n",
    "    normalization_stats['center_x'] = float(normalizer.center_x)\n",
    "    normalization_stats['center_y'] = float(normalizer.center_y)\n",
    "    normalization_stats['scale'] = float(normalizer.scale)\n",
    "\n",
    "deployment_info = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'input_dim': CONFIG['input_dim'],\n",
    "        'd_model': CONFIG['d_model'], \n",
    "        'nhead': CONFIG['nhead'],\n",
    "        'num_layers': CONFIG['num_layers'],\n",
    "        'num_classes': len(class_names),\n",
    "        'seq_len': CONFIG['max_seq_len'],\n",
    "        'dropout': CONFIG['dropout']\n",
    "    },\n",
    "    'class_names': class_names,\n",
    "    'class_mapping': {\n",
    "        'word_to_idx': train_dataset.word_to_idx,\n",
    "        'idx_to_word': train_dataset.idx_to_word\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'best_val_acc': final_best_acc,\n",
    "        'test_acc': test_accuracy * 100 if 'test_accuracy' in locals() else 0.0,\n",
    "        'total_params': total_params,\n",
    "        'trainable_params': trainable_params\n",
    "    },\n",
    "    'training_config': CONFIG,\n",
    "    'normalization_stats': normalization_stats\n",
    "}\n",
    "\n",
    "torch.save(deployment_info, final_model_path)\n",
    "print(f\"‚úÖ Final model saved to: {final_model_path}\")\n",
    "\n",
    "# Export model architecture summary\n",
    "print(f\"\\nüìã Model Architecture Summary:\")\n",
    "print(f\"  Input Shape: (batch_size, {CONFIG['max_seq_len']}, {CONFIG['input_dim']})\")\n",
    "print(f\"  Output Shape: (batch_size, {len(class_names)})\")\n",
    "print(f\"  Model Size: {total_params * 4 / 1024 / 1024:.1f} MB\")\n",
    "print(f\"  Inference Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Create inference example\n",
    "print(f\"\\nüîÆ Creating inference example...\")\n",
    "sample_input = torch.randn(1, CONFIG['max_seq_len'], CONFIG['input_dim']).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_output = model(sample_input)\n",
    "    predicted_class_idx = torch.argmax(sample_output, dim=1).item()\n",
    "    predicted_class = class_names[predicted_class_idx]\n",
    "    confidence = torch.softmax(sample_output, dim=1).max().item()\n",
    "\n",
    "print(f\"‚úÖ Inference test successful!\")\n",
    "print(f\"  Sample prediction: {predicted_class} (confidence: {confidence:.3f})\")\n",
    "\n",
    "print(f\"\\nüéØ Model is ready for deployment and inference!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aslpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
